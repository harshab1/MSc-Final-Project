{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from unicodedata import normalize\n",
    "import numpy\n",
    "from numpy import array\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN,GRU,LSTM\n",
    "from keras.layers import Dense, Embedding, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archive:  fra-eng.zip',\n",
       " 'replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n",
       " '(EOF or read error, treating as \"[N]one\" ...)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching and decompressing the dataset \n",
    "!!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
    "!!unzip fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the text data preserving the Unicode french characters\n",
    "\n",
    "def load_doc(filename):\n",
    "    \n",
    "\t# opening the text file in read only mode with unicode encoding \n",
    "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
    "    \n",
    "\t# reading the text from the opened file\n",
    "\ttext = file.read()\n",
    "    \n",
    "\t# finally closing the file\n",
    "\tfile.close()\n",
    "    \n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each line of the text file contain English sentence and its French translation seperated by tab character.  \n",
    "\n",
    "def to_pairs(doc):\n",
    "    \n",
    "    # Obtaining each line in the file\n",
    "\tlines = doc.strip().split('\\n')\n",
    "    \n",
    "    # Obtaining the pairs of English sentence and its french translation\n",
    "\tpairs = [line.split('\\t') for line in  lines]\n",
    "    \n",
    "\treturn pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the lines by removing all the non-printable characters, punctuation characters\n",
    "# clean a list of lines\n",
    "def clean_pairs(lines):\n",
    "    \n",
    "\tcleaned = list()\n",
    "    \n",
    "\t# using regular expression for removing non-printable characters\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    \n",
    "\t# using regular expression for removing punctuation characters and obtaining translation table\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "    \n",
    "\tfor pair in lines:\n",
    "        \n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "            \n",
    "\t\t\t# normalization to remove canonical and compatibility related issues\n",
    "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\t\tline = line.decode('UTF-8')\n",
    "            \n",
    "\t\t\t# tokenizing the white space\n",
    "\t\t\tline = line.split()\n",
    "            \n",
    "\t\t\t# normalizing the text to lowercase\n",
    "\t\t\tline = [word.lower() for word in line]\n",
    "            \n",
    "\t\t\t# removing punctuation from each token using regular expression table \n",
    "\t\t\tline = [word.translate(table) for word in line]\n",
    "            \n",
    "\t\t\t# removing non-printable characters using the above regular expression\n",
    "\t\t\tline = [re_print.sub('', w) for w in line]\n",
    "            \n",
    "\t\t\t# removing the non-alphabetic tokens such as numbers\n",
    "\t\t\tline = [word for word in line if word.isalpha()]\n",
    "            \n",
    "\t\t\t# store as string\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the text dataset\n",
    "filename = 'fra.txt'\n",
    "doc = load_doc(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the lines in the text file into english-french pairs\n",
    "pairs = to_pairs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the sentences\n",
    "clean_pairs = clean_pairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: eng-fre.pkl\n"
     ]
    }
   ],
   "source": [
    "# saving the cleaned pairs to file\n",
    "save_clean_data(clean_pairs, 'eng-fre.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There a total of 190206 pairs of tranlations in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Total number of translation sentences\n",
    "print(\"There a total of {} pairs of tranlations in the dataset\".format(clean_pairs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English : turn to the right\n",
      "French : tournez a droite sil vous plait \n",
      "\n",
      "English : why did you stay home yesterday\n",
      "French : pourquoi estu reste chez toi hier \n",
      "\n",
      "English : this is irrelevant\n",
      "French : cest hors de propos \n",
      "\n",
      "English : i lost my balance\n",
      "French : jai perdu lequilibre \n",
      "\n",
      "English : why do you say one thing and then go and do another\n",
      "French : pourquoi distu une chose et ensuite tu y vas et tu fais autre chose \n",
      "\n",
      "English : i am the same age\n",
      "French : je suis du meme age \n",
      "\n",
      "English : dont change a thing\n",
      "French : ne changez rien \n",
      "\n",
      "English : give me a sec\n",
      "French : donnemoi une seconde \n",
      "\n",
      "English : i thought it was very easy\n",
      "French : je pensais que cetait du gateau \n",
      "\n",
      "English : his house was struck by lightning\n",
      "French : sa maison a ete frappee par la foudre \n",
      "\n",
      "English : well take it\n",
      "French : nous le prendrons \n",
      "\n",
      "English : youre being weird\n",
      "French : tes pas normal \n",
      "\n",
      "English : whatever you do dont blink\n",
      "French : quoi que tu fasses ne cligne pas les yeux \n",
      "\n",
      "English : its not irrelevant\n",
      "French : ce nest pas horssujet \n",
      "\n",
      "English : i shouldve guessed youd be busy\n",
      "French : jaurais du deviner que tu serais occupee \n",
      "\n",
      "English : youre depressed arent you\n",
      "French : vous etes deprime nestce pas \n",
      "\n",
      "English : we were too optimistic\n",
      "French : nous etions trop optimistes \n",
      "\n",
      "English : i talked to the girl you told me about\n",
      "French : jai parle a la fille dont tu mas parle \n",
      "\n",
      "English : lets do something different\n",
      "French : faisons quelque chose de different \n",
      "\n",
      "English : i ate a turkey sandwich\n",
      "French : jai mange un sandwich a la dinde \n",
      "\n",
      "English : the cause of the accident is a complete mystery\n",
      "French : la cause de laccident est un mystere complet \n",
      "\n",
      "English : i will finish it by tomorrow afternoon\n",
      "French : je le finirai avant demain apresmidi \n",
      "\n",
      "English : who do you trust\n",
      "French : en qui astu confiance \n",
      "\n",
      "English : are we safe\n",
      "French : sommesnous en securite \n",
      "\n",
      "English : she blamed her failure on bad luck\n",
      "French : elle mit son echec sur le compte de la malchance \n",
      "\n",
      "English : i need that information as soon as possible\n",
      "French : jai besoin de cette information des que possible \n",
      "\n",
      "English : its a great start\n",
      "French : cest un grand debut \n",
      "\n",
      "English : ill finish it in two or three minutes\n",
      "French : je vais le terminer dans deux ou trois minutes \n",
      "\n",
      "English : are you sure you dont want something a little smaller\n",
      "French : etesvous sur de ne pas vouloir quelque chose dun peu plus petit \n",
      "\n",
      "English : does he know how she feels about him\n",
      "French : saitil ce quelle eprouve a son egard \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Looking at few sentences\n",
    "\n",
    "rand_list = random.sample(range(0, clean_pairs.shape[0]), 30)\n",
    "for i in rand_list:\n",
    "\tprint('English : %s\\nFrench : %s \\n' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the previously cleaned data \n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "\tdump(sentences, open(filename, 'wb'))\n",
    "\tprint('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the raw dataset\n",
    "raw_dataset = load_clean_sentences('eng-fre.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are over 190000 pairs of sentences, it will take long time for training and testing the model\n",
    "# Hence dataset size is reduced\n",
    "n_sentences = 50000 #clean_pairs.shape[0]\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "train_size = numpy.rint(0.7 * n_sentences)\n",
    "validation_size = numpy.rint(0.1 * n_sentences)\n",
    "test_size = numpy.rint(0.2 * n_sentences)\n",
    "\n",
    "# randomly shuffling the dataset\n",
    "shuffle(dataset)\n",
    "\n",
    "# spliting the reduced dataset into train, validation and test\n",
    "split_1 = int(train_size)\n",
    "split_2 = int(train_size+validation_size)\n",
    "split_3 = int(train_size+validation_size+test_size)\n",
    "train, validation, test = dataset[:split_1], dataset[split_1:split_2], dataset[split_2:split_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 3), (5000, 3), (10000, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: eng-fre-total.pkl\n",
      "Saved: eng-fre-train.pkl\n",
      "Saved: eng-fre-validation.pkl\n",
      "Saved: eng-fre-test.pkl\n"
     ]
    }
   ],
   "source": [
    "# saving the reduced dataset to training, validation and testing data\n",
    "\n",
    "save_clean_data(dataset, 'eng-fre-total.pkl')\n",
    "save_clean_data(train, 'eng-fre-train.pkl')\n",
    "save_clean_data(validation, 'eng-fre-validation.pkl')\n",
    "save_clean_data(test, 'eng-fre-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the previously cleaned dataset \n",
    "\n",
    "def load_clean_sentences(filename):\n",
    "\treturn load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using keras tokenize class, for mapping the words to integers needed for modeling\n",
    "\n",
    "def create_tokenizer(lines):\n",
    "\ttokenizer = Tokenizer()\n",
    "\ttokenizer.fit_on_texts(lines)\n",
    "\treturn tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the maximum sentence length from the list of phrases \n",
    "\n",
    "def max_length(lines):\n",
    "\treturn max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and padding the input and output sequences\n",
    "\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# Each input and output sequence are  encoded to integers\n",
    "\tX = tokenizer.texts_to_sequences(lines)\n",
    "\t# Obtained sequences are padded with 0 values at the end to make their lenght as maxmim phrase length\n",
    "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output target sequences (English sentences) has to be one hot encoded as the model will \n",
    "# predicts probability of each word in the vocabulary as output. \n",
    "\n",
    "def encode_output(sequences, vocab_size):\n",
    "\tylist = list()\n",
    "\tfor sequence in sequences:\n",
    "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "\t\tylist.append(encoded)\n",
    "\ty = array(ylist)\n",
    "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "\treturn y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping an predicted sequence of integers to a words by looking up tokenizer\n",
    "\n",
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the sequence of integers for generating string of words\n",
    "\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the performance of each model using BLEU score by comparing predicted result to original/expected sequences \n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "\tactual, predicted = list(), list()\n",
    "\tbleu_scores = []\n",
    "\tfor i, source in enumerate(sources):\n",
    "\t\t# translating the encoded input text sequence\n",
    "\t\tsource = source.reshape((1, source.shape[0]))\n",
    "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
    "\t\traw_target, raw_src = raw_dataset[i][0], raw_dataset[i][1]\n",
    "        \n",
    "        # Printing 50 French to English translations by the model\n",
    "        \n",
    "\t\tif i < 50:\n",
    "\t\t\tprint('French(Source) : %s\\nTarget : %s\\nPredicted : %s \\n' % (raw_src, raw_target, translation))\n",
    "        \n",
    "        \n",
    "\t\tactual.append([raw_target.split()])\n",
    "\t\tpredicted.append(translation.split())\n",
    "        \n",
    "    # Calculating BLEU score\n",
    "\tbleu_1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
    "\tbleu_2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
    "\tbleu_3 = corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0))\n",
    "\tbleu_4 = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    \n",
    "    # Saving BLEU scores to return \n",
    "\tbleu_scores = [bleu_1, bleu_2, bleu_3, bleu_4]\n",
    "    \n",
    "                         \n",
    "\t# calculate BLEU score\n",
    "\tprint('BLEU-1: %f' % bleu_1)\n",
    "\tprint('BLEU-2: %f' % bleu_2)\n",
    "\tprint('BLEU-3: %f' % bleu_3)\n",
    "\tprint('BLEU-4: %f' % bleu_4)\n",
    "    \n",
    "\treturn bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the total, train, validation and test datasets \n",
    "dataset = load_clean_sentences('eng-fre-total.pkl')\n",
    "train = load_clean_sentences('eng-fre-train.pkl')\n",
    "valid = load_clean_sentences('eng-fre-validation.pkl')\n",
    "test = load_clean_sentences('eng-fre-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6010\n",
      "English Max Length: 7\n",
      "French Vocabulary Size: 12184\n",
      "French Max Length: 14\n"
     ]
    }
   ],
   "source": [
    "# preparing the English tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))\\\n",
    "\n",
    "# preparing the French tokenizer\n",
    "fre_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
    "fre_length = max_length(dataset[:, 1])\n",
    "print('French Vocabulary Size: %d' % fre_vocab_size)\n",
    "print('French Max Length: %d' % (fre_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 1,\n",
       " 'you': 2,\n",
       " 'tom': 3,\n",
       " 'a': 4,\n",
       " 'is': 5,\n",
       " 'it': 6,\n",
       " 'the': 7,\n",
       " 'to': 8,\n",
       " 'im': 9,\n",
       " 'he': 10,\n",
       " 'me': 11,\n",
       " 'this': 12,\n",
       " 'do': 13,\n",
       " 'was': 14,\n",
       " 'that': 15,\n",
       " 'youre': 16,\n",
       " 'are': 17,\n",
       " 'we': 18,\n",
       " 'have': 19,\n",
       " 'dont': 20,\n",
       " 'your': 21,\n",
       " 'my': 22,\n",
       " 'not': 23,\n",
       " 'were': 24,\n",
       " 'its': 25,\n",
       " 'go': 26,\n",
       " 'did': 27,\n",
       " 'be': 28,\n",
       " 'can': 29,\n",
       " 'they': 30,\n",
       " 'like': 31,\n",
       " 'all': 32,\n",
       " 'no': 33,\n",
       " 'in': 34,\n",
       " 'what': 35,\n",
       " 'she': 36,\n",
       " 'very': 37,\n",
       " 'of': 38,\n",
       " 'here': 39,\n",
       " 'want': 40,\n",
       " 'how': 41,\n",
       " 'ill': 42,\n",
       " 'get': 43,\n",
       " 'on': 44,\n",
       " 'thats': 45,\n",
       " 'know': 46,\n",
       " 'need': 47,\n",
       " 'cant': 48,\n",
       " 'up': 49,\n",
       " 'one': 50,\n",
       " 'for': 51,\n",
       " 'him': 52,\n",
       " 'out': 53,\n",
       " 'so': 54,\n",
       " 'at': 55,\n",
       " 'now': 56,\n",
       " 'good': 57,\n",
       " 'just': 58,\n",
       " 'love': 59,\n",
       " 'come': 60,\n",
       " 'please': 61,\n",
       " 'help': 62,\n",
       " 'has': 63,\n",
       " 'there': 64,\n",
       " 'too': 65,\n",
       " 'why': 66,\n",
       " 'theyre': 67,\n",
       " 'look': 68,\n",
       " 'who': 69,\n",
       " 'got': 70,\n",
       " 'us': 71,\n",
       " 'hes': 72,\n",
       " 'lets': 73,\n",
       " 'will': 74,\n",
       " 'see': 75,\n",
       " 'take': 76,\n",
       " 'his': 77,\n",
       " 'had': 78,\n",
       " 'am': 79,\n",
       " 'let': 80,\n",
       " 'well': 81,\n",
       " 'think': 82,\n",
       " 'stop': 83,\n",
       " 'with': 84,\n",
       " 'an': 85,\n",
       " 'home': 86,\n",
       " 'her': 87,\n",
       " 'didnt': 88,\n",
       " 'back': 89,\n",
       " 'really': 90,\n",
       " 'happy': 91,\n",
       " 'give': 92,\n",
       " 'must': 93,\n",
       " 'right': 94,\n",
       " 'feel': 95,\n",
       " 'keep': 96,\n",
       " 'ive': 97,\n",
       " 'try': 98,\n",
       " 'work': 99,\n",
       " 'them': 100,\n",
       " 'still': 101,\n",
       " 'where': 102,\n",
       " 'car': 103,\n",
       " 'made': 104,\n",
       " 'toms': 105,\n",
       " 'going': 106,\n",
       " 'may': 107,\n",
       " 'never': 108,\n",
       " 'alone': 109,\n",
       " 'whats': 110,\n",
       " 'leave': 111,\n",
       " 'eat': 112,\n",
       " 'stay': 113,\n",
       " 'busy': 114,\n",
       " 'about': 115,\n",
       " 'looks': 116,\n",
       " 'french': 117,\n",
       " 'saw': 118,\n",
       " 'time': 119,\n",
       " 'isnt': 120,\n",
       " 'again': 121,\n",
       " 'lost': 122,\n",
       " 'mary': 123,\n",
       " 'went': 124,\n",
       " 'does': 125,\n",
       " 'dog': 126,\n",
       " 'make': 127,\n",
       " 'down': 128,\n",
       " 'big': 129,\n",
       " 'everyone': 130,\n",
       " 'wont': 131,\n",
       " 'ready': 132,\n",
       " 'job': 133,\n",
       " 'some': 134,\n",
       " 'off': 135,\n",
       " 'hate': 136,\n",
       " 'felt': 137,\n",
       " 'should': 138,\n",
       " 'bad': 139,\n",
       " 'say': 140,\n",
       " 'today': 141,\n",
       " 'tell': 142,\n",
       " 'drink': 143,\n",
       " 'away': 144,\n",
       " 'could': 145,\n",
       " 'old': 146,\n",
       " 'tired': 147,\n",
       " 'wait': 148,\n",
       " 'much': 149,\n",
       " 'nice': 150,\n",
       " 'lot': 151,\n",
       " 'money': 152,\n",
       " 'book': 153,\n",
       " 'room': 154,\n",
       " 'call': 155,\n",
       " 'left': 156,\n",
       " 'hear': 157,\n",
       " 'talk': 158,\n",
       " 'our': 159,\n",
       " 'new': 160,\n",
       " 'enough': 161,\n",
       " 'wrong': 162,\n",
       " 'been': 163,\n",
       " 'hurt': 164,\n",
       " 'fun': 165,\n",
       " 'seems': 166,\n",
       " 'said': 167,\n",
       " 'done': 168,\n",
       " 'find': 169,\n",
       " 'id': 170,\n",
       " 'sure': 171,\n",
       " 'day': 172,\n",
       " 'over': 173,\n",
       " 'way': 174,\n",
       " 'hard': 175,\n",
       " 'house': 176,\n",
       " 'wheres': 177,\n",
       " 'everybody': 178,\n",
       " 'door': 179,\n",
       " 'came': 180,\n",
       " 'everything': 181,\n",
       " 'open': 182,\n",
       " 'wasnt': 183,\n",
       " 'safe': 184,\n",
       " 'mine': 185,\n",
       " 'hope': 186,\n",
       " 'late': 187,\n",
       " 'live': 188,\n",
       " 'kept': 189,\n",
       " 'bed': 190,\n",
       " 'likes': 191,\n",
       " 'gave': 192,\n",
       " 'speak': 193,\n",
       " 'read': 194,\n",
       " 'anyone': 195,\n",
       " 'more': 196,\n",
       " 'better': 197,\n",
       " 'friends': 198,\n",
       " 'yet': 199,\n",
       " 'both': 200,\n",
       " 'sorry': 201,\n",
       " 'ask': 202,\n",
       " 'idea': 203,\n",
       " 'easy': 204,\n",
       " 'would': 205,\n",
       " 'turn': 206,\n",
       " 'watch': 207,\n",
       " 'found': 208,\n",
       " 'shes': 209,\n",
       " 'nothing': 210,\n",
       " 'cold': 211,\n",
       " 'play': 212,\n",
       " 'whos': 213,\n",
       " 'broke': 214,\n",
       " 'when': 215,\n",
       " 'friend': 216,\n",
       " 'funny': 217,\n",
       " 'these': 218,\n",
       " 'man': 219,\n",
       " 'water': 220,\n",
       " 'something': 221,\n",
       " 'trust': 222,\n",
       " 'and': 223,\n",
       " 'sleep': 224,\n",
       " 'knew': 225,\n",
       " 'heard': 226,\n",
       " 'buy': 227,\n",
       " 'true': 228,\n",
       " 'long': 229,\n",
       " 'yours': 230,\n",
       " 'by': 231,\n",
       " 'careful': 232,\n",
       " 'ok': 233,\n",
       " 'died': 234,\n",
       " 'took': 235,\n",
       " 'youve': 236,\n",
       " 'as': 237,\n",
       " 'loves': 238,\n",
       " 'teacher': 239,\n",
       " 'great': 240,\n",
       " 'nobody': 241,\n",
       " 'hungry': 242,\n",
       " 'put': 243,\n",
       " 'hurry': 244,\n",
       " 'run': 245,\n",
       " 'life': 246,\n",
       " 'remember': 247,\n",
       " 'only': 248,\n",
       " 'miss': 249,\n",
       " 'show': 250,\n",
       " 'doing': 251,\n",
       " 'sick': 252,\n",
       " 'theres': 253,\n",
       " 'win': 254,\n",
       " 'crazy': 255,\n",
       " 'gone': 256,\n",
       " 'sit': 257,\n",
       " 'use': 258,\n",
       " 'already': 259,\n",
       " 'fast': 260,\n",
       " 'told': 261,\n",
       " 'coming': 262,\n",
       " 'best': 263,\n",
       " 'school': 264,\n",
       " 'pay': 265,\n",
       " 'cat': 266,\n",
       " 'anybody': 267,\n",
       " 'from': 268,\n",
       " 'being': 269,\n",
       " 'wanted': 270,\n",
       " 'angry': 271,\n",
       " 'yourself': 272,\n",
       " 'knows': 273,\n",
       " 'problem': 274,\n",
       " 'dead': 275,\n",
       " 'anything': 276,\n",
       " 'started': 277,\n",
       " 'kind': 278,\n",
       " 'close': 279,\n",
       " 'boy': 280,\n",
       " 'die': 281,\n",
       " 'forget': 282,\n",
       " 'arent': 283,\n",
       " 'believe': 284,\n",
       " 'mean': 285,\n",
       " 'tomorrow': 286,\n",
       " 'called': 287,\n",
       " 'eyes': 288,\n",
       " 'name': 289,\n",
       " 'early': 290,\n",
       " 'any': 291,\n",
       " 'always': 292,\n",
       " 'liked': 293,\n",
       " 'little': 294,\n",
       " 'bring': 295,\n",
       " 'sing': 296,\n",
       " 'sat': 297,\n",
       " 'mother': 298,\n",
       " 'tried': 299,\n",
       " 'upset': 300,\n",
       " 'looked': 301,\n",
       " 'quiet': 302,\n",
       " 'answer': 303,\n",
       " 'quit': 304,\n",
       " 'swim': 305,\n",
       " 'stupid': 306,\n",
       " 'bit': 307,\n",
       " 'talking': 308,\n",
       " 'pretty': 309,\n",
       " 'afraid': 310,\n",
       " 'won': 311,\n",
       " 'move': 312,\n",
       " 'two': 313,\n",
       " 'start': 314,\n",
       " 'care': 315,\n",
       " 'if': 316,\n",
       " 'ran': 317,\n",
       " 'doesnt': 318,\n",
       " 'almost': 319,\n",
       " 'fine': 320,\n",
       " 'glad': 321,\n",
       " 'outside': 322,\n",
       " 'soon': 323,\n",
       " 'drive': 324,\n",
       " 'wants': 325,\n",
       " 'beer': 326,\n",
       " 'walk': 327,\n",
       " 'hot': 328,\n",
       " 'free': 329,\n",
       " 'those': 330,\n",
       " 'food': 331,\n",
       " 'scared': 332,\n",
       " 'married': 333,\n",
       " 'mad': 334,\n",
       " 'sad': 335,\n",
       " 'working': 336,\n",
       " 'hat': 337,\n",
       " 'met': 338,\n",
       " 'thanks': 339,\n",
       " 'drunk': 340,\n",
       " 'kids': 341,\n",
       " 'weve': 342,\n",
       " 'hows': 343,\n",
       " 'used': 344,\n",
       " 'lucky': 345,\n",
       " 'change': 346,\n",
       " 'lie': 347,\n",
       " 'hand': 348,\n",
       " 'myself': 349,\n",
       " 'many': 350,\n",
       " 'shot': 351,\n",
       " 'works': 352,\n",
       " 'once': 353,\n",
       " 'fell': 354,\n",
       " 'tall': 355,\n",
       " 'last': 356,\n",
       " 'night': 357,\n",
       " 'coffee': 358,\n",
       " 'serious': 359,\n",
       " 'bought': 360,\n",
       " 'perfect': 361,\n",
       " 'stand': 362,\n",
       " 'check': 363,\n",
       " 'handle': 364,\n",
       " 'seat': 365,\n",
       " 'shut': 366,\n",
       " 'changed': 367,\n",
       " 'lunch': 368,\n",
       " 'needs': 369,\n",
       " 'first': 370,\n",
       " 'study': 371,\n",
       " 'stopped': 372,\n",
       " 'touch': 373,\n",
       " 'enjoy': 374,\n",
       " 'ate': 375,\n",
       " 'tea': 376,\n",
       " 'light': 377,\n",
       " 'word': 378,\n",
       " 'fired': 379,\n",
       " 'listen': 380,\n",
       " 'around': 381,\n",
       " 'finished': 382,\n",
       " 'hair': 383,\n",
       " 'often': 384,\n",
       " 'thought': 385,\n",
       " 'books': 386,\n",
       " 'tv': 387,\n",
       " 'wish': 388,\n",
       " 'write': 389,\n",
       " 'wine': 390,\n",
       " 'doctor': 391,\n",
       " 'key': 392,\n",
       " 'phone': 393,\n",
       " 'plan': 394,\n",
       " 'choice': 395,\n",
       " 'meet': 396,\n",
       " 'mind': 397,\n",
       " 'seen': 398,\n",
       " 'next': 399,\n",
       " 'fish': 400,\n",
       " 'theyll': 401,\n",
       " 'forgot': 402,\n",
       " 'music': 403,\n",
       " 'needed': 404,\n",
       " 'rest': 405,\n",
       " 'quite': 406,\n",
       " 'fat': 407,\n",
       " 'father': 408,\n",
       " 'dinner': 409,\n",
       " 'into': 410,\n",
       " 'bus': 411,\n",
       " 'proud': 412,\n",
       " 'red': 413,\n",
       " 'getting': 414,\n",
       " 'hands': 415,\n",
       " 'three': 416,\n",
       " 'cool': 417,\n",
       " 'son': 418,\n",
       " 'born': 419,\n",
       " 'loved': 420,\n",
       " 'which': 421,\n",
       " 'wife': 422,\n",
       " 'leaving': 423,\n",
       " 'maybe': 424,\n",
       " 'lose': 425,\n",
       " 'naive': 426,\n",
       " 'story': 427,\n",
       " 'caught': 428,\n",
       " 'running': 429,\n",
       " 'eating': 430,\n",
       " 'sounds': 431,\n",
       " 'paid': 432,\n",
       " 'guy': 433,\n",
       " 'guess': 434,\n",
       " 'rich': 435,\n",
       " 'clean': 436,\n",
       " 'dream': 437,\n",
       " 'someone': 438,\n",
       " 'kidding': 439,\n",
       " 'dogs': 440,\n",
       " 'inside': 441,\n",
       " 'luck': 442,\n",
       " 'weird': 443,\n",
       " 'such': 444,\n",
       " 'liar': 445,\n",
       " 'place': 446,\n",
       " 'ahead': 447,\n",
       " 'agree': 448,\n",
       " 'quickly': 449,\n",
       " 'nervous': 450,\n",
       " 'understand': 451,\n",
       " 'follow': 452,\n",
       " 'whose': 453,\n",
       " 'seem': 454,\n",
       " 'asked': 455,\n",
       " 'hit': 456,\n",
       " 'kiss': 457,\n",
       " 'reading': 458,\n",
       " 'boston': 459,\n",
       " 'else': 460,\n",
       " 'together': 461,\n",
       " 'invited': 462,\n",
       " 'lying': 463,\n",
       " 'bicycle': 464,\n",
       " 'hates': 465,\n",
       " 'girl': 466,\n",
       " 'itll': 467,\n",
       " 'confused': 468,\n",
       " 'nuts': 469,\n",
       " 'happened': 470,\n",
       " 'young': 471,\n",
       " 'own': 472,\n",
       " 'game': 473,\n",
       " 'asleep': 474,\n",
       " 'surprised': 475,\n",
       " 'crying': 476,\n",
       " 'cute': 477,\n",
       " 'arrived': 478,\n",
       " 'youll': 479,\n",
       " 'warned': 480,\n",
       " 'break': 481,\n",
       " 'gun': 482,\n",
       " 'missed': 483,\n",
       " 'wake': 484,\n",
       " 'milk': 485,\n",
       " 'fix': 486,\n",
       " 'began': 487,\n",
       " 'song': 488,\n",
       " 'bag': 489,\n",
       " 'cake': 490,\n",
       " 'than': 491,\n",
       " 'couldnt': 492,\n",
       " 'owe': 493,\n",
       " 'shoes': 494,\n",
       " 'thing': 495,\n",
       " 'yesterday': 496,\n",
       " 'another': 497,\n",
       " 'youd': 498,\n",
       " 'helped': 499,\n",
       " 'smart': 500,\n",
       " 'laughed': 501,\n",
       " 'drop': 502,\n",
       " 'deal': 503,\n",
       " 'strong': 504,\n",
       " 'child': 505,\n",
       " 'awesome': 506,\n",
       " 'worked': 507,\n",
       " 'hold': 508,\n",
       " 'excited': 509,\n",
       " 'heres': 510,\n",
       " 'might': 511,\n",
       " 'cut': 512,\n",
       " 'or': 513,\n",
       " 'lied': 514,\n",
       " 'cry': 515,\n",
       " 'kill': 516,\n",
       " 'ones': 517,\n",
       " 'trouble': 518,\n",
       " 'spoke': 519,\n",
       " 'became': 520,\n",
       " 'killed': 521,\n",
       " 'real': 522,\n",
       " 'minute': 523,\n",
       " 'alive': 524,\n",
       " 'turned': 525,\n",
       " 'people': 526,\n",
       " 'things': 527,\n",
       " 'sleepy': 528,\n",
       " 'calm': 529,\n",
       " 'writing': 530,\n",
       " 'joke': 531,\n",
       " 'lives': 532,\n",
       " 'worried': 533,\n",
       " 'family': 534,\n",
       " 'head': 535,\n",
       " 'broken': 536,\n",
       " 'sweet': 537,\n",
       " 'beautiful': 538,\n",
       " 'waited': 539,\n",
       " 'fault': 540,\n",
       " 'happen': 541,\n",
       " 'walked': 542,\n",
       " 'sister': 543,\n",
       " 'girls': 544,\n",
       " 'thank': 545,\n",
       " 'behind': 546,\n",
       " 'far': 547,\n",
       " 'beat': 548,\n",
       " 'even': 549,\n",
       " 'week': 550,\n",
       " 'sound': 551,\n",
       " 'fight': 552,\n",
       " 'fire': 553,\n",
       " 'rain': 554,\n",
       " 'news': 555,\n",
       " 'guys': 556,\n",
       " 'catch': 557,\n",
       " 'lonely': 558,\n",
       " 'normal': 559,\n",
       " 'lazy': 560,\n",
       " 'every': 561,\n",
       " 'singing': 562,\n",
       " 'count': 563,\n",
       " 'face': 564,\n",
       " 'cats': 565,\n",
       " 'sign': 566,\n",
       " 'different': 567,\n",
       " 'pen': 568,\n",
       " 'chance': 569,\n",
       " 'clever': 570,\n",
       " 'empty': 571,\n",
       " 'children': 572,\n",
       " 'horse': 573,\n",
       " 'jealous': 574,\n",
       " 'trying': 575,\n",
       " 'smoke': 576,\n",
       " 'movie': 577,\n",
       " 'team': 578,\n",
       " 'brave': 579,\n",
       " 'smell': 580,\n",
       " 'upstairs': 581,\n",
       " 'after': 582,\n",
       " 'satisfied': 583,\n",
       " 'coat': 584,\n",
       " 'same': 585,\n",
       " 'cried': 586,\n",
       " 'blame': 587,\n",
       " 'box': 588,\n",
       " 'fair': 589,\n",
       " 'wonderful': 590,\n",
       " 'saved': 591,\n",
       " 'small': 592,\n",
       " 'student': 593,\n",
       " 'boss': 594,\n",
       " 'keys': 595,\n",
       " 'heart': 596,\n",
       " 'age': 597,\n",
       " 'makes': 598,\n",
       " 'dance': 599,\n",
       " 'curious': 600,\n",
       " 'prepared': 601,\n",
       " 'betrayed': 602,\n",
       " 'watching': 603,\n",
       " 'danger': 604,\n",
       " 'terrible': 605,\n",
       " 'mom': 606,\n",
       " 'tonight': 607,\n",
       " 'somebody': 608,\n",
       " 'shocked': 609,\n",
       " 'dark': 610,\n",
       " 'tie': 611,\n",
       " 'worry': 612,\n",
       " 'important': 613,\n",
       " 'sent': 614,\n",
       " 'looking': 615,\n",
       " 'trusted': 616,\n",
       " 'bike': 617,\n",
       " 'drinking': 618,\n",
       " 'silent': 619,\n",
       " 'baby': 620,\n",
       " 'camera': 621,\n",
       " 'amazing': 622,\n",
       " 'tough': 623,\n",
       " 'slow': 624,\n",
       " 'later': 625,\n",
       " 'drank': 626,\n",
       " 'hurts': 627,\n",
       " 'apple': 628,\n",
       " 'fit': 629,\n",
       " 'send': 630,\n",
       " 'person': 631,\n",
       " 'window': 632,\n",
       " 'boat': 633,\n",
       " 'list': 634,\n",
       " 'smiled': 635,\n",
       " 'joking': 636,\n",
       " 'ride': 637,\n",
       " 'finally': 638,\n",
       " 'yes': 639,\n",
       " 'shy': 640,\n",
       " 'studying': 641,\n",
       " 'followed': 642,\n",
       " 'duty': 643,\n",
       " 'correct': 644,\n",
       " 'polite': 645,\n",
       " 'hug': 646,\n",
       " 'short': 647,\n",
       " 'warn': 648,\n",
       " 'japanese': 649,\n",
       " 'slowly': 650,\n",
       " 'idiot': 651,\n",
       " 'god': 652,\n",
       " 'full': 653,\n",
       " 'awful': 654,\n",
       " 'thirsty': 655,\n",
       " 'lock': 656,\n",
       " 'rules': 657,\n",
       " 'arm': 658,\n",
       " 'nose': 659,\n",
       " 'table': 660,\n",
       " 'rude': 661,\n",
       " 'kid': 662,\n",
       " 'english': 663,\n",
       " 'wrote': 664,\n",
       " 'bet': 665,\n",
       " 'prefer': 666,\n",
       " 'honest': 667,\n",
       " 'act': 668,\n",
       " 'mistake': 669,\n",
       " 'step': 670,\n",
       " 'feels': 671,\n",
       " 'involved': 672,\n",
       " 'failed': 673,\n",
       " 'laugh': 674,\n",
       " 'excuse': 675,\n",
       " 'fool': 676,\n",
       " 'fly': 677,\n",
       " 'closed': 678,\n",
       " 'lawyer': 679,\n",
       " 'secret': 680,\n",
       " 'bored': 681,\n",
       " 'daughter': 682,\n",
       " 'tight': 683,\n",
       " 'comes': 684,\n",
       " 'opened': 685,\n",
       " 'blue': 686,\n",
       " 'expect': 687,\n",
       " 'playing': 688,\n",
       " 'town': 689,\n",
       " 'dirty': 690,\n",
       " 'dancing': 691,\n",
       " 'grab': 692,\n",
       " 'sleeping': 693,\n",
       " 'meant': 694,\n",
       " 'seemed': 695,\n",
       " 'explain': 696,\n",
       " 'woke': 697,\n",
       " 'talked': 698,\n",
       " 'possible': 699,\n",
       " 'trip': 700,\n",
       " 'message': 701,\n",
       " 'terrific': 702,\n",
       " 'ignore': 703,\n",
       " 'moving': 704,\n",
       " 'few': 705,\n",
       " 'boring': 706,\n",
       " 'teach': 707,\n",
       " 'vote': 708,\n",
       " 'oldest': 709,\n",
       " 'picture': 710,\n",
       " 'party': 711,\n",
       " 'retired': 712,\n",
       " 'impatient': 713,\n",
       " 'winning': 714,\n",
       " 'their': 715,\n",
       " 'unlucky': 716,\n",
       " 'having': 717,\n",
       " 'shirt': 718,\n",
       " 'smiling': 719,\n",
       " 'wise': 720,\n",
       " 'awake': 721,\n",
       " 'save': 722,\n",
       " 'huge': 723,\n",
       " 'laughing': 724,\n",
       " 'relax': 725,\n",
       " 'relaxed': 726,\n",
       " 'chair': 727,\n",
       " 'cook': 728,\n",
       " 'deserve': 729,\n",
       " 'wet': 730,\n",
       " 'slept': 731,\n",
       " 'tree': 732,\n",
       " 'listening': 733,\n",
       " 'order': 734,\n",
       " 'exhausted': 735,\n",
       " 'believed': 736,\n",
       " 'meat': 737,\n",
       " 'feeling': 738,\n",
       " 'pain': 739,\n",
       " 'cops': 740,\n",
       " 'death': 741,\n",
       " 'taking': 742,\n",
       " 'end': 743,\n",
       " 'weak': 744,\n",
       " 'hang': 745,\n",
       " 'faster': 746,\n",
       " 'snow': 747,\n",
       " 'cooking': 748,\n",
       " 'dangerous': 749,\n",
       " 'pizza': 750,\n",
       " 'expensive': 751,\n",
       " 'travel': 752,\n",
       " 'before': 753,\n",
       " 'parents': 754,\n",
       " 'ugly': 755,\n",
       " 'patient': 756,\n",
       " 'kissed': 757,\n",
       " 'ours': 758,\n",
       " 'shall': 759,\n",
       " 'talented': 760,\n",
       " 'smells': 761,\n",
       " 'sense': 762,\n",
       " 'timid': 763,\n",
       " 'famous': 764,\n",
       " 'point': 765,\n",
       " 'dying': 766,\n",
       " 'stayed': 767,\n",
       " 'apologize': 768,\n",
       " 'shopping': 769,\n",
       " 'forward': 770,\n",
       " 'shower': 771,\n",
       " 'says': 772,\n",
       " 'welcome': 773,\n",
       " 'woman': 774,\n",
       " 'hired': 775,\n",
       " 'men': 776,\n",
       " 'then': 777,\n",
       " 'skinny': 778,\n",
       " 'strange': 779,\n",
       " 'begin': 780,\n",
       " 'refused': 781,\n",
       " 'blind': 782,\n",
       " 'truth': 783,\n",
       " 'closer': 784,\n",
       " 'second': 785,\n",
       " 'feet': 786,\n",
       " 'guilty': 787,\n",
       " 'push': 788,\n",
       " 'join': 789,\n",
       " 'cannot': 790,\n",
       " 'downstairs': 791,\n",
       " 'high': 792,\n",
       " 'hey': 793,\n",
       " 'jump': 794,\n",
       " 'cheated': 795,\n",
       " 'brother': 796,\n",
       " 'smarter': 797,\n",
       " 'bill': 798,\n",
       " 'dress': 799,\n",
       " 'longer': 800,\n",
       " 'glasses': 801,\n",
       " 'prove': 802,\n",
       " 'watched': 803,\n",
       " 'drives': 804,\n",
       " 'near': 805,\n",
       " 'cup': 806,\n",
       " 'choose': 807,\n",
       " 'set': 808,\n",
       " 'map': 809,\n",
       " 'class': 810,\n",
       " 'white': 811,\n",
       " 'deep': 812,\n",
       " 'finish': 813,\n",
       " 'warm': 814,\n",
       " 'tastes': 815,\n",
       " 'clothes': 816,\n",
       " 'continue': 817,\n",
       " 'touched': 818,\n",
       " 'decided': 819,\n",
       " 'interested': 820,\n",
       " 'baked': 821,\n",
       " 'war': 822,\n",
       " 'air': 823,\n",
       " 'respect': 824,\n",
       " 'matter': 825,\n",
       " 'everyones': 826,\n",
       " 'eggs': 827,\n",
       " 'driving': 828,\n",
       " 'bath': 829,\n",
       " 'doors': 830,\n",
       " 'date': 831,\n",
       " 'depressed': 832,\n",
       " 'black': 833,\n",
       " 'pencil': 834,\n",
       " 'waiting': 835,\n",
       " 'train': 836,\n",
       " 'speaks': 837,\n",
       " 'breath': 838,\n",
       " 'park': 839,\n",
       " 'hardly': 840,\n",
       " 'clock': 841,\n",
       " 'escape': 842,\n",
       " 'control': 843,\n",
       " 'throw': 844,\n",
       " 'monday': 845,\n",
       " 'whatre': 846,\n",
       " 'hero': 847,\n",
       " 'dressed': 848,\n",
       " 'losing': 849,\n",
       " 'disgusting': 850,\n",
       " 'smile': 851,\n",
       " 'making': 852,\n",
       " 'risk': 853,\n",
       " 'charge': 854,\n",
       " 'moment': 855,\n",
       " 'rid': 856,\n",
       " 'agreed': 857,\n",
       " 'clear': 858,\n",
       " 'sharp': 859,\n",
       " 'knife': 860,\n",
       " 'rather': 861,\n",
       " 'allowed': 862,\n",
       " 'under': 863,\n",
       " 'impressed': 864,\n",
       " 'line': 865,\n",
       " 'fake': 866,\n",
       " 'raining': 867,\n",
       " 'ordered': 868,\n",
       " 'brought': 869,\n",
       " 'apples': 870,\n",
       " 'share': 871,\n",
       " 'bite': 872,\n",
       " 'decision': 873,\n",
       " 'advice': 874,\n",
       " 'poor': 875,\n",
       " 'yelling': 876,\n",
       " 'law': 877,\n",
       " 'without': 878,\n",
       " 'mess': 879,\n",
       " 'plays': 880,\n",
       " 'worth': 881,\n",
       " 'six': 882,\n",
       " 'wash': 883,\n",
       " 'convinced': 884,\n",
       " 'refuse': 885,\n",
       " 'ago': 886,\n",
       " 'naked': 887,\n",
       " 'cash': 888,\n",
       " 'along': 889,\n",
       " 'students': 890,\n",
       " 'learn': 891,\n",
       " 'shoot': 892,\n",
       " 'business': 893,\n",
       " 'boys': 894,\n",
       " 'breakfast': 895,\n",
       " 'cruel': 896,\n",
       " 'direct': 897,\n",
       " 'obey': 898,\n",
       " 'protect': 899,\n",
       " 'mouth': 900,\n",
       " 'office': 901,\n",
       " 'survive': 902,\n",
       " 'hated': 903,\n",
       " 'innocent': 904,\n",
       " 'fighting': 905,\n",
       " 'side': 906,\n",
       " 'christmas': 907,\n",
       " 'year': 908,\n",
       " 'forgive': 909,\n",
       " 'totally': 910,\n",
       " 'ball': 911,\n",
       " 'stunned': 912,\n",
       " 'pleased': 913,\n",
       " 'carefully': 914,\n",
       " 'also': 915,\n",
       " 'grow': 916,\n",
       " 'ideas': 917,\n",
       " 'cost': 918,\n",
       " 'wear': 919,\n",
       " 'tomll': 920,\n",
       " 'enemy': 921,\n",
       " 'gift': 922,\n",
       " 'trapped': 923,\n",
       " 'smoking': 924,\n",
       " 'helps': 925,\n",
       " 'bird': 926,\n",
       " 'havent': 927,\n",
       " 'bell': 928,\n",
       " 'beg': 929,\n",
       " 'helping': 930,\n",
       " 'holiday': 931,\n",
       " 'simple': 932,\n",
       " 'himself': 933,\n",
       " 'drinks': 934,\n",
       " 'lovely': 935,\n",
       " 'favor': 936,\n",
       " 'stuck': 937,\n",
       " 'promise': 938,\n",
       " 'letter': 939,\n",
       " 'silly': 940,\n",
       " 'bank': 941,\n",
       " 'piano': 942,\n",
       " 'paper': 943,\n",
       " 'homework': 944,\n",
       " 'relieved': 945,\n",
       " 'locked': 946,\n",
       " 'other': 947,\n",
       " 'cautious': 948,\n",
       " 'eye': 949,\n",
       " 'swimming': 950,\n",
       " 'generous': 951,\n",
       " 'fantastic': 952,\n",
       " 'anymore': 953,\n",
       " 'jokes': 954,\n",
       " 'match': 955,\n",
       " 'pick': 956,\n",
       " 'special': 957,\n",
       " 'lit': 958,\n",
       " 'friendly': 959,\n",
       " 'missing': 960,\n",
       " 'speaking': 961,\n",
       " 'rope': 962,\n",
       " 'hi': 963,\n",
       " 'pardon': 964,\n",
       " 'weight': 965,\n",
       " 'built': 966,\n",
       " 'flight': 967,\n",
       " 'concerned': 968,\n",
       " 'decide': 969,\n",
       " 'raise': 970,\n",
       " 'days': 971,\n",
       " 'while': 972,\n",
       " 'summer': 973,\n",
       " 'legs': 974,\n",
       " 'deny': 975,\n",
       " 'creative': 976,\n",
       " 'chose': 977,\n",
       " 'seated': 978,\n",
       " 'question': 979,\n",
       " 'fed': 980,\n",
       " 'nearly': 981,\n",
       " 'afford': 982,\n",
       " 'goal': 983,\n",
       " 'cookies': 984,\n",
       " 'foolish': 985,\n",
       " 'low': 986,\n",
       " 'unbelievable': 987,\n",
       " 'fishing': 988,\n",
       " 'aside': 989,\n",
       " 'grew': 990,\n",
       " 'horrible': 991,\n",
       " 'fever': 992,\n",
       " 'useless': 993,\n",
       " 'gets': 994,\n",
       " 'truck': 995,\n",
       " 'pull': 996,\n",
       " 'ambitious': 997,\n",
       " 'dry': 998,\n",
       " 'address': 999,\n",
       " 'remain': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word index of English tokenizer\n",
    "eng_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'je': 1,\n",
       " 'tom': 2,\n",
       " 'pas': 3,\n",
       " 'a': 4,\n",
       " 'de': 5,\n",
       " 'vous': 6,\n",
       " 'ne': 7,\n",
       " 'est': 8,\n",
       " 'il': 9,\n",
       " 'le': 10,\n",
       " 'nous': 11,\n",
       " 'la': 12,\n",
       " 'suis': 13,\n",
       " 'cest': 14,\n",
       " 'jai': 15,\n",
       " 'un': 16,\n",
       " 'tu': 17,\n",
       " 'que': 18,\n",
       " 'en': 19,\n",
       " 'me': 20,\n",
       " 'une': 21,\n",
       " 'ca': 22,\n",
       " 'les': 23,\n",
       " 'ce': 24,\n",
       " 'etes': 25,\n",
       " 'tout': 26,\n",
       " 'elle': 27,\n",
       " 'sont': 28,\n",
       " 'fait': 29,\n",
       " 'qui': 30,\n",
       " 'estce': 31,\n",
       " 'sommes': 32,\n",
       " 'mon': 33,\n",
       " 'ils': 34,\n",
       " 'des': 35,\n",
       " 'es': 36,\n",
       " 'ma': 37,\n",
       " 'te': 38,\n",
       " 'faire': 39,\n",
       " 'tres': 40,\n",
       " 'nest': 41,\n",
       " 'du': 42,\n",
       " 'elles': 43,\n",
       " 'cela': 44,\n",
       " 'votre': 45,\n",
       " 'se': 46,\n",
       " 'bien': 47,\n",
       " 'ete': 48,\n",
       " 'y': 49,\n",
       " 'besoin': 50,\n",
       " 'ici': 51,\n",
       " 'lair': 52,\n",
       " 'veux': 53,\n",
       " 'peux': 54,\n",
       " 'pour': 55,\n",
       " 'moi': 56,\n",
       " 'personne': 57,\n",
       " 'etesvous': 58,\n",
       " 'etait': 59,\n",
       " 'comment': 60,\n",
       " 'ton': 61,\n",
       " 'ou': 62,\n",
       " 'pourquoi': 63,\n",
       " 'aller': 64,\n",
       " 'tous': 65,\n",
       " 'avons': 66,\n",
       " 'dans': 67,\n",
       " 'toi': 68,\n",
       " 'si': 69,\n",
       " 'au': 70,\n",
       " 'monde': 71,\n",
       " 'sur': 72,\n",
       " 'avec': 73,\n",
       " 'sest': 74,\n",
       " 'maintenant': 75,\n",
       " 'faut': 76,\n",
       " 'plus': 77,\n",
       " 'jaime': 78,\n",
       " 'va': 79,\n",
       " 'cette': 80,\n",
       " 'trop': 81,\n",
       " 'on': 82,\n",
       " 'as': 83,\n",
       " 'train': 84,\n",
       " 'bon': 85,\n",
       " 'nai': 86,\n",
       " 'ai': 87,\n",
       " 'cetait': 88,\n",
       " 'vraiment': 89,\n",
       " 'estu': 90,\n",
       " 'sais': 91,\n",
       " 'ont': 92,\n",
       " 'fais': 93,\n",
       " 'lui': 94,\n",
       " 'ta': 95,\n",
       " 'jetais': 96,\n",
       " 'etre': 97,\n",
       " 'maison': 98,\n",
       " 'avez': 99,\n",
       " 'dit': 100,\n",
       " 'ceci': 101,\n",
       " 'encore': 102,\n",
       " 'astu': 103,\n",
       " 'pense': 104,\n",
       " 'puisje': 105,\n",
       " 'toutes': 106,\n",
       " 'vais': 107,\n",
       " 'avezvous': 108,\n",
       " 'lai': 109,\n",
       " 'jamais': 110,\n",
       " 'plait': 111,\n",
       " 'mal': 112,\n",
       " 'soyez': 113,\n",
       " 'voiture': 114,\n",
       " 'dois': 115,\n",
       " 'son': 116,\n",
       " 'quelle': 117,\n",
       " 'sens': 118,\n",
       " 'comme': 119,\n",
       " 'peut': 120,\n",
       " 'vu': 121,\n",
       " 'beaucoup': 122,\n",
       " 'sil': 123,\n",
       " 'francais': 124,\n",
       " 'rien': 125,\n",
       " 'partir': 126,\n",
       " 'temps': 127,\n",
       " 'deux': 128,\n",
       " 'peu': 129,\n",
       " 'sois': 130,\n",
       " 'na': 131,\n",
       " 'quel': 132,\n",
       " 'fort': 133,\n",
       " 'juste': 134,\n",
       " 'mes': 135,\n",
       " 'chien': 136,\n",
       " 'deteste': 137,\n",
       " 'estil': 138,\n",
       " 'tes': 139,\n",
       " 'quoi': 140,\n",
       " 'voir': 141,\n",
       " 'jadore': 142,\n",
       " 'porte': 143,\n",
       " 'aujourdhui': 144,\n",
       " 'aime': 145,\n",
       " 'bonne': 146,\n",
       " 'ny': 147,\n",
       " 'chez': 148,\n",
       " 'questce': 149,\n",
       " 'chose': 150,\n",
       " 'travail': 151,\n",
       " 'trouve': 152,\n",
       " 'toujours': 153,\n",
       " 'dun': 154,\n",
       " 'perdu': 155,\n",
       " 'arrete': 156,\n",
       " 'quelque': 157,\n",
       " 'atil': 158,\n",
       " 'viens': 159,\n",
       " 'heureux': 160,\n",
       " 'seul': 161,\n",
       " 'faites': 162,\n",
       " 'reste': 163,\n",
       " 'livre': 164,\n",
       " 'semble': 165,\n",
       " 'men': 166,\n",
       " 'marie': 167,\n",
       " 'tellement': 168,\n",
       " 'jen': 169,\n",
       " 'parle': 170,\n",
       " 'regarde': 171,\n",
       " 'assez': 172,\n",
       " 'parler': 173,\n",
       " 'nouveau': 174,\n",
       " 'prie': 175,\n",
       " 'pris': 176,\n",
       " 'avait': 177,\n",
       " 'quelquun': 178,\n",
       " 'mange': 179,\n",
       " 'nen': 180,\n",
       " 'eu': 181,\n",
       " 'notre': 182,\n",
       " 'dire': 183,\n",
       " 'laisse': 184,\n",
       " 'manger': 185,\n",
       " 'mieux': 186,\n",
       " 'deja': 187,\n",
       " 'avoir': 188,\n",
       " 'confiance': 189,\n",
       " 'peur': 190,\n",
       " 'fut': 191,\n",
       " 'quil': 192,\n",
       " 'passe': 193,\n",
       " 'vie': 194,\n",
       " 'quand': 195,\n",
       " 'dune': 196,\n",
       " 'pouvez': 197,\n",
       " 'chambre': 198,\n",
       " 'et': 199,\n",
       " 'vos': 200,\n",
       " 'aije': 201,\n",
       " 'occupe': 202,\n",
       " 'raison': 203,\n",
       " 'connais': 204,\n",
       " 'simplement': 205,\n",
       " 'aider': 206,\n",
       " 'idee': 207,\n",
       " 'aussi': 208,\n",
       " 'lit': 209,\n",
       " 'grand': 210,\n",
       " 'pret': 211,\n",
       " 'restez': 212,\n",
       " 'soit': 213,\n",
       " 'prends': 214,\n",
       " 'combien': 215,\n",
       " 'sa': 216,\n",
       " 'vite': 217,\n",
       " 'par': 218,\n",
       " 'netes': 219,\n",
       " 'detre': 220,\n",
       " 'entendu': 221,\n",
       " 'travaille': 222,\n",
       " 'faim': 223,\n",
       " 'non': 224,\n",
       " 'mort': 225,\n",
       " 'coup': 226,\n",
       " 'arrive': 227,\n",
       " 'daccord': 228,\n",
       " 'prendre': 229,\n",
       " 'demande': 230,\n",
       " 'malade': 231,\n",
       " 'probleme': 232,\n",
       " 'mere': 233,\n",
       " 'tai': 234,\n",
       " 'jy': 235,\n",
       " 'marche': 236,\n",
       " 'fini': 237,\n",
       " 'fatigue': 238,\n",
       " 'sait': 239,\n",
       " 'gros': 240,\n",
       " 'gagne': 241,\n",
       " 'vrai': 242,\n",
       " 'boulot': 243,\n",
       " 'peuxtu': 244,\n",
       " 'allez': 245,\n",
       " 'pouvons': 246,\n",
       " 'mary': 247,\n",
       " 'dis': 248,\n",
       " 'arretez': 249,\n",
       " 'laissemoi': 250,\n",
       " 'chance': 251,\n",
       " 'venir': 252,\n",
       " 'merci': 253,\n",
       " 'yeux': 254,\n",
       " 'sans': 255,\n",
       " 'continue': 256,\n",
       " 'veuillez': 257,\n",
       " 'ces': 258,\n",
       " 'peutetre': 259,\n",
       " 'naime': 260,\n",
       " 'aux': 261,\n",
       " 'prenez': 262,\n",
       " 'pouvezvous': 263,\n",
       " 'homme': 264,\n",
       " 'enfants': 265,\n",
       " 'demain': 266,\n",
       " 'mauvais': 267,\n",
       " 'travailler': 268,\n",
       " 'commence': 269,\n",
       " 'colere': 270,\n",
       " 'tete': 271,\n",
       " 'termine': 272,\n",
       " 'heureuse': 273,\n",
       " 'netait': 274,\n",
       " 'veut': 275,\n",
       " 'parti': 276,\n",
       " 'tard': 277,\n",
       " 'securite': 278,\n",
       " 'seule': 279,\n",
       " 'essaye': 280,\n",
       " 'manque': 281,\n",
       " 'chanter': 282,\n",
       " 'femme': 283,\n",
       " 'laissezmoi': 284,\n",
       " 'sen': 285,\n",
       " 'pourrait': 286,\n",
       " 'achete': 287,\n",
       " 'main': 288,\n",
       " 'nager': 289,\n",
       " 'voici': 290,\n",
       " 'fille': 291,\n",
       " 'ami': 292,\n",
       " 'leau': 293,\n",
       " 'retard': 294,\n",
       " 'jespere': 295,\n",
       " 'etions': 296,\n",
       " 'froid': 297,\n",
       " 'dehors': 298,\n",
       " 'donne': 299,\n",
       " 'journee': 300,\n",
       " 'aide': 301,\n",
       " 'rester': 302,\n",
       " 'mis': 303,\n",
       " 'allons': 304,\n",
       " 'facile': 305,\n",
       " 'chat': 306,\n",
       " 'regardez': 307,\n",
       " 'jaimerais': 308,\n",
       " 'lire': 309,\n",
       " 'oublie': 310,\n",
       " 'nes': 311,\n",
       " 'biere': 312,\n",
       " 'aucun': 313,\n",
       " 'age': 314,\n",
       " 'adore': 315,\n",
       " 'verre': 316,\n",
       " 'meme': 317,\n",
       " 'attention': 318,\n",
       " 'calme': 319,\n",
       " 'alle': 320,\n",
       " 'amis': 321,\n",
       " 'garcon': 322,\n",
       " 'chercher': 323,\n",
       " 'presque': 324,\n",
       " 'senti': 325,\n",
       " 'lecole': 326,\n",
       " 'joue': 327,\n",
       " 'dispose': 328,\n",
       " 'etaient': 329,\n",
       " 'vient': 330,\n",
       " 'ses': 331,\n",
       " 'mourir': 332,\n",
       " 'vieux': 333,\n",
       " 'blesse': 334,\n",
       " 'choix': 335,\n",
       " 'heures': 336,\n",
       " 'chapeau': 337,\n",
       " 'ferme': 338,\n",
       " 'nom': 339,\n",
       " 'prete': 340,\n",
       " 'estelle': 341,\n",
       " 'pere': 342,\n",
       " 'ten': 343,\n",
       " 'crois': 344,\n",
       " 'serai': 345,\n",
       " 'doit': 346,\n",
       " 'difficile': 347,\n",
       " 'grande': 348,\n",
       " 'dur': 349,\n",
       " 'toute': 350,\n",
       " 'tot': 351,\n",
       " 'largent': 352,\n",
       " 'venez': 353,\n",
       " 'vois': 354,\n",
       " 'fils': 355,\n",
       " 'garde': 356,\n",
       " 'bientot': 357,\n",
       " 'tort': 358,\n",
       " 'telephone': 359,\n",
       " 'cafe': 360,\n",
       " 'narrive': 361,\n",
       " 'fois': 362,\n",
       " 'venu': 363,\n",
       " 'souvent': 364,\n",
       " 'occupee': 365,\n",
       " 'quiconque': 366,\n",
       " 'voulais': 367,\n",
       " 'desole': 368,\n",
       " 'tranquille': 369,\n",
       " 'triste': 370,\n",
       " 'cote': 371,\n",
       " 'place': 372,\n",
       " 'tomber': 373,\n",
       " 'dargent': 374,\n",
       " 'fou': 375,\n",
       " 'petit': 376,\n",
       " 'vue': 377,\n",
       " 'voulons': 378,\n",
       " 'enfant': 379,\n",
       " 'essayer': 380,\n",
       " 'suisje': 381,\n",
       " 'casse': 382,\n",
       " 'dormir': 383,\n",
       " 'donnemoi': 384,\n",
       " 'sortir': 385,\n",
       " 'appele': 386,\n",
       " 'devons': 387,\n",
       " 'vin': 388,\n",
       " 'cheveux': 389,\n",
       " 'aucune': 390,\n",
       " 'sagit': 391,\n",
       " 'nuit': 392,\n",
       " 'trouver': 393,\n",
       " 'drole': 394,\n",
       " 'velo': 395,\n",
       " 'laide': 396,\n",
       " 'lheure': 397,\n",
       " 'essaie': 398,\n",
       " 'plutot': 399,\n",
       " 'devrais': 400,\n",
       " 'pleurer': 401,\n",
       " 'javais': 402,\n",
       " 'the': 403,\n",
       " 'bizarre': 404,\n",
       " 'vis': 405,\n",
       " 'dejeuner': 406,\n",
       " 'entrer': 407,\n",
       " 'idiot': 408,\n",
       " 'content': 409,\n",
       " 'compte': 410,\n",
       " 'nestce': 411,\n",
       " 'assis': 412,\n",
       " 'cet': 413,\n",
       " 'change': 414,\n",
       " 'arme': 415,\n",
       " 'pouvonsnous': 416,\n",
       " 'trois': 417,\n",
       " 'nourriture': 418,\n",
       " 'gagner': 419,\n",
       " 'musique': 420,\n",
       " 'serieux': 421,\n",
       " 'autre': 422,\n",
       " 'debout': 423,\n",
       " 'mauvaise': 424,\n",
       " 'chaud': 425,\n",
       " 'partie': 426,\n",
       " 'voulezvous': 427,\n",
       " 'bus': 428,\n",
       " 'payer': 429,\n",
       " 'peuvent': 430,\n",
       " 'dy': 431,\n",
       " 'sontils': 432,\n",
       " 'veuxtu': 433,\n",
       " 'tire': 434,\n",
       " 'rapidement': 435,\n",
       " 'sors': 436,\n",
       " 'devez': 437,\n",
       " 'savais': 438,\n",
       " 'bois': 439,\n",
       " 'gentil': 440,\n",
       " 'marcher': 441,\n",
       " 'hier': 442,\n",
       " 'point': 443,\n",
       " 'courir': 444,\n",
       " 'jouer': 445,\n",
       " 'livres': 446,\n",
       " 'davantage': 447,\n",
       " 'riche': 448,\n",
       " 'boire': 449,\n",
       " 'attendre': 450,\n",
       " 'photo': 451,\n",
       " 'ville': 452,\n",
       " 'chemin': 453,\n",
       " 'apres': 454,\n",
       " 'boston': 455,\n",
       " 'chiens': 456,\n",
       " 'savoir': 457,\n",
       " 'court': 458,\n",
       " 'sac': 459,\n",
       " 'sera': 460,\n",
       " 'rendre': 461,\n",
       " 'histoire': 462,\n",
       " 'ensemble': 463,\n",
       " 'laissez': 464,\n",
       " 'ecrit': 465,\n",
       " 'tue': 466,\n",
       " 'sommesnous': 467,\n",
       " 'chanson': 468,\n",
       " 'voila': 469,\n",
       " 'apprecie': 470,\n",
       " 'plan': 471,\n",
       " 'leur': 472,\n",
       " 'bras': 473,\n",
       " 'piece': 474,\n",
       " 'egalement': 475,\n",
       " 'reponse': 476,\n",
       " 'jour': 477,\n",
       " 'libre': 478,\n",
       " 'feu': 479,\n",
       " 'moment': 480,\n",
       " 'japprecie': 481,\n",
       " 'lavezvous': 482,\n",
       " 'netais': 483,\n",
       " 'touche': 484,\n",
       " 'cle': 485,\n",
       " 'navons': 486,\n",
       " 'paye': 487,\n",
       " 'nouvelle': 488,\n",
       " 'amusant': 489,\n",
       " 'blague': 490,\n",
       " 'aimestu': 491,\n",
       " 'jeune': 492,\n",
       " 'devenu': 493,\n",
       " 'linterieur': 494,\n",
       " 'danser': 495,\n",
       " 'faute': 496,\n",
       " 'regarder': 497,\n",
       " 'montre': 498,\n",
       " 'pensais': 499,\n",
       " 'lastu': 500,\n",
       " 'filles': 501,\n",
       " 'prudent': 502,\n",
       " 'lait': 503,\n",
       " 'desormais': 504,\n",
       " 'donnezmoi': 505,\n",
       " 'desolee': 506,\n",
       " 'medecin': 507,\n",
       " 'fatiguee': 508,\n",
       " 'plein': 509,\n",
       " 'soir': 510,\n",
       " 'mains': 511,\n",
       " 'perdre': 512,\n",
       " 'beau': 513,\n",
       " 'reve': 514,\n",
       " 'menti': 515,\n",
       " 'vieille': 516,\n",
       " 'rouge': 517,\n",
       " 'chaussures': 518,\n",
       " 'souviens': 519,\n",
       " 'meilleur': 520,\n",
       " 'sontelles': 521,\n",
       " 'cur': 522,\n",
       " 'voyage': 523,\n",
       " 'leve': 524,\n",
       " 'semaine': 525,\n",
       " 'nimporte': 526,\n",
       " 'prix': 527,\n",
       " 'continuez': 528,\n",
       " 'famille': 529,\n",
       " 'jirai': 530,\n",
       " 'rire': 531,\n",
       " 'conduire': 532,\n",
       " 'belle': 533,\n",
       " 'quon': 534,\n",
       " 'part': 535,\n",
       " 'dautre': 536,\n",
       " 'parfait': 537,\n",
       " 'rentrer': 538,\n",
       " 'labas': 539,\n",
       " 'pres': 540,\n",
       " 'fonctionne': 541,\n",
       " 'cuisine': 542,\n",
       " 'choses': 543,\n",
       " 'fit': 544,\n",
       " 'sortez': 545,\n",
       " 'ferai': 546,\n",
       " 'fier': 547,\n",
       " 'gateau': 548,\n",
       " 'danger': 549,\n",
       " 'faisons': 550,\n",
       " 'attrape': 551,\n",
       " 'aimezvous': 552,\n",
       " 'surpris': 553,\n",
       " 'taider': 554,\n",
       " 'my': 555,\n",
       " 'super': 556,\n",
       " 'chats': 557,\n",
       " 'pleure': 558,\n",
       " 'vit': 559,\n",
       " 'dites': 560,\n",
       " 'dessus': 561,\n",
       " 'poisson': 562,\n",
       " 'compris': 563,\n",
       " 'prudente': 564,\n",
       " 'bateau': 565,\n",
       " 'courant': 566,\n",
       " 'lavons': 567,\n",
       " 'pars': 568,\n",
       " 'marrant': 569,\n",
       " 'cheval': 570,\n",
       " 'ecoute': 571,\n",
       " 'tombe': 572,\n",
       " 'essayez': 573,\n",
       " 'stylo': 574,\n",
       " 'lamour': 575,\n",
       " 'connait': 576,\n",
       " 'argent': 577,\n",
       " 'boite': 578,\n",
       " 'laime': 579,\n",
       " 'minute': 580,\n",
       " 'attends': 581,\n",
       " 'sympa': 582,\n",
       " 'carte': 583,\n",
       " 'derriere': 584,\n",
       " 'reveille': 585,\n",
       " 'ainsi': 586,\n",
       " 'etais': 587,\n",
       " 'vide': 588,\n",
       " 'prefere': 589,\n",
       " 'rencontrer': 590,\n",
       " 'veulent': 591,\n",
       " 'type': 592,\n",
       " 'loin': 593,\n",
       " 'devraisje': 594,\n",
       " 'premier': 595,\n",
       " 'commande': 596,\n",
       " 'arreter': 597,\n",
       " 'diner': 598,\n",
       " 'refuse': 599,\n",
       " 'erreur': 600,\n",
       " 'film': 601,\n",
       " 'amie': 602,\n",
       " 'bonnes': 603,\n",
       " 'heure': 604,\n",
       " 'dormi': 605,\n",
       " 'lont': 606,\n",
       " 'mot': 607,\n",
       " 'avance': 608,\n",
       " 'professeur': 609,\n",
       " 'sommeil': 610,\n",
       " 'bureau': 611,\n",
       " 'quun': 612,\n",
       " 'jusqua': 613,\n",
       " 'mien': 614,\n",
       " 'attendez': 615,\n",
       " 'genial': 616,\n",
       " 'cours': 617,\n",
       " 'manteau': 618,\n",
       " 'grosse': 619,\n",
       " 'entendre': 620,\n",
       " 'immediatement': 621,\n",
       " 'sagitil': 622,\n",
       " 'lentement': 623,\n",
       " 'intelligent': 624,\n",
       " 'sure': 625,\n",
       " 'envie': 626,\n",
       " 'pretes': 627,\n",
       " 'prets': 628,\n",
       " 'satisfait': 629,\n",
       " 'dieu': 630,\n",
       " 'quils': 631,\n",
       " 'cesse': 632,\n",
       " 'reviens': 633,\n",
       " 'pourrais': 634,\n",
       " 'oui': 635,\n",
       " 'parlez': 636,\n",
       " 'chante': 637,\n",
       " 'timide': 638,\n",
       " 'prepare': 639,\n",
       " 'nez': 640,\n",
       " 'table': 641,\n",
       " 'pommes': 642,\n",
       " 'propre': 643,\n",
       " 'vers': 644,\n",
       " 'contente': 645,\n",
       " 'liste': 646,\n",
       " 'taille': 647,\n",
       " 'reussi': 648,\n",
       " 'celuici': 649,\n",
       " 'vont': 650,\n",
       " 'reparer': 651,\n",
       " 'plaisir': 652,\n",
       " 'mas': 653,\n",
       " 'faux': 654,\n",
       " 'forme': 655,\n",
       " 'alors': 656,\n",
       " 'quelques': 657,\n",
       " 'tour': 658,\n",
       " 'demander': 659,\n",
       " 'rencontre': 660,\n",
       " 'rendu': 661,\n",
       " 'bu': 662,\n",
       " 'stupide': 663,\n",
       " 'obtenu': 664,\n",
       " 'seconde': 665,\n",
       " 'etiezvous': 666,\n",
       " 'espoir': 667,\n",
       " 'question': 668,\n",
       " 'soif': 669,\n",
       " 'quitte': 670,\n",
       " 'cles': 671,\n",
       " 'pied': 672,\n",
       " 'neige': 673,\n",
       " 'taime': 674,\n",
       " 'normal': 675,\n",
       " 'derange': 676,\n",
       " 'fenetre': 677,\n",
       " 'peutil': 678,\n",
       " 'mentir': 679,\n",
       " 'ouvert': 680,\n",
       " 'parole': 681,\n",
       " 'ferais': 682,\n",
       " 'sentis': 683,\n",
       " 'lis': 684,\n",
       " 'pomme': 685,\n",
       " 'douche': 686,\n",
       " 'ans': 687,\n",
       " 'possible': 688,\n",
       " 'secret': 689,\n",
       " 'entre': 690,\n",
       " 'completement': 691,\n",
       " 'verite': 692,\n",
       " 'chaise': 693,\n",
       " 'invite': 694,\n",
       " 'peine': 695,\n",
       " 'vas': 696,\n",
       " 'suppose': 697,\n",
       " 'signe': 698,\n",
       " 'gardez': 699,\n",
       " 'lun': 700,\n",
       " 'dentre': 701,\n",
       " 'faisait': 702,\n",
       " 'tele': 703,\n",
       " 'chemise': 704,\n",
       " 'saistu': 705,\n",
       " 'battre': 706,\n",
       " 'occupes': 707,\n",
       " 'sous': 708,\n",
       " 'endroit': 709,\n",
       " 'utiliser': 710,\n",
       " 'deau': 711,\n",
       " 'jeu': 712,\n",
       " 'note': 713,\n",
       " 'parviens': 714,\n",
       " 'dici': 715,\n",
       " 'sent': 716,\n",
       " 'fete': 717,\n",
       " 'retraite': 718,\n",
       " 'incroyable': 719,\n",
       " 'recu': 720,\n",
       " 'quastu': 721,\n",
       " 'regles': 722,\n",
       " 'aimes': 723,\n",
       " 'etiez': 724,\n",
       " 'maider': 725,\n",
       " 'nos': 726,\n",
       " 'frere': 727,\n",
       " 'avocat': 728,\n",
       " 'message': 729,\n",
       " 'vraie': 730,\n",
       " 'retourne': 731,\n",
       " 'sujet': 732,\n",
       " 'merite': 733,\n",
       " 'jaurais': 734,\n",
       " 'rentre': 735,\n",
       " 'menteur': 736,\n",
       " 'ri': 737,\n",
       " 'lunettes': 738,\n",
       " 'nouvelles': 739,\n",
       " 'pieds': 740,\n",
       " 'terre': 741,\n",
       " 'rapide': 742,\n",
       " 'amies': 743,\n",
       " 'taxi': 744,\n",
       " 'vole': 745,\n",
       " 'bebe': 746,\n",
       " 'devrions': 747,\n",
       " 'nerveux': 748,\n",
       " 'silencieux': 749,\n",
       " 'bicyclette': 750,\n",
       " 'vote': 751,\n",
       " 'voulez': 752,\n",
       " 'tourne': 753,\n",
       " 'excuses': 754,\n",
       " 'compter': 755,\n",
       " 'quelles': 756,\n",
       " 'gens': 757,\n",
       " 'rend': 758,\n",
       " 'pizza': 759,\n",
       " 'davoir': 760,\n",
       " 'quy': 761,\n",
       " 'neuf': 762,\n",
       " 'service': 763,\n",
       " 'fermez': 764,\n",
       " 'tiens': 765,\n",
       " 'sourire': 766,\n",
       " 'monte': 767,\n",
       " 'horrible': 768,\n",
       " 'droit': 769,\n",
       " 'pu': 770,\n",
       " 'mienne': 771,\n",
       " 'mont': 772,\n",
       " 'petite': 773,\n",
       " 'sentie': 774,\n",
       " 'haut': 775,\n",
       " 'savezvous': 776,\n",
       " 'comprends': 777,\n",
       " 'lune': 778,\n",
       " 'coute': 779,\n",
       " 'retour': 780,\n",
       " 'viande': 781,\n",
       " 'folle': 782,\n",
       " 'changer': 783,\n",
       " 'etaitce': 784,\n",
       " 'jarrive': 785,\n",
       " 'fus': 786,\n",
       " 'devrait': 787,\n",
       " 'etudier': 788,\n",
       " 'laise': 789,\n",
       " 'jours': 790,\n",
       " 'parents': 791,\n",
       " 'apporte': 792,\n",
       " 'mets': 793,\n",
       " 'gentille': 794,\n",
       " 'avais': 795,\n",
       " 'television': 796,\n",
       " 'idiote': 797,\n",
       " 'visage': 798,\n",
       " 'suffit': 799,\n",
       " 'eux': 800,\n",
       " 'risque': 801,\n",
       " 'important': 802,\n",
       " 'simple': 803,\n",
       " 'amoureux': 804,\n",
       " 'bas': 805,\n",
       " 'seuls': 806,\n",
       " 'lequel': 807,\n",
       " 'classe': 808,\n",
       " 'seules': 809,\n",
       " 'bouge': 810,\n",
       " 'decide': 811,\n",
       " 'quavezvous': 812,\n",
       " 'navez': 813,\n",
       " 'equipe': 814,\n",
       " 'honnete': 815,\n",
       " 'curieux': 816,\n",
       " 'moins': 817,\n",
       " 'possede': 818,\n",
       " 'faisle': 819,\n",
       " 'mavez': 820,\n",
       " 'embrasse': 821,\n",
       " 'lumiere': 822,\n",
       " 'mesure': 823,\n",
       " 'sauve': 824,\n",
       " 'verifie': 825,\n",
       " 'lexterieur': 826,\n",
       " 'donner': 827,\n",
       " 'coupe': 828,\n",
       " 'bain': 829,\n",
       " 'sy': 830,\n",
       " 'suffisamment': 831,\n",
       " 'sale': 832,\n",
       " 'envoye': 833,\n",
       " 'frappe': 834,\n",
       " 'commencer': 835,\n",
       " 'nas': 836,\n",
       " 'tasse': 837,\n",
       " 'pouvais': 838,\n",
       " 'dont': 839,\n",
       " 'sentait': 840,\n",
       " 'savez': 841,\n",
       " 'marreter': 842,\n",
       " 'different': 843,\n",
       " 'horreur': 844,\n",
       " 'patron': 845,\n",
       " 'voix': 846,\n",
       " 'fis': 847,\n",
       " 'mignon': 848,\n",
       " 'chouette': 849,\n",
       " 'pause': 850,\n",
       " 'morts': 851,\n",
       " 'occupees': 852,\n",
       " 'siege': 853,\n",
       " 'etudie': 854,\n",
       " 'avant': 855,\n",
       " 'arriver': 856,\n",
       " 'abandonne': 857,\n",
       " 'voudrais': 858,\n",
       " 'disparu': 859,\n",
       " 'allee': 860,\n",
       " 'guerre': 861,\n",
       " 'rappelle': 862,\n",
       " 'suite': 863,\n",
       " 'souhaite': 864,\n",
       " 'confectionne': 865,\n",
       " 'delle': 866,\n",
       " 'gars': 867,\n",
       " 'voulait': 868,\n",
       " 'flics': 869,\n",
       " 'morte': 870,\n",
       " 'emploi': 871,\n",
       " 'cadeau': 872,\n",
       " 'jentends': 873,\n",
       " 'ecrire': 874,\n",
       " 'crie': 875,\n",
       " 'heureuses': 876,\n",
       " 'paresseux': 877,\n",
       " 'fumer': 878,\n",
       " 'daide': 879,\n",
       " 'cuisiner': 880,\n",
       " 'garder': 881,\n",
       " 'dangereux': 882,\n",
       " 'dingue': 883,\n",
       " 'fous': 884,\n",
       " 'attendu': 885,\n",
       " 'rarement': 886,\n",
       " 'daller': 887,\n",
       " 'serais': 888,\n",
       " 'bons': 889,\n",
       " 'heros': 890,\n",
       " 'vire': 891,\n",
       " 'allezvous': 892,\n",
       " 'jaloux': 893,\n",
       " 'droite': 894,\n",
       " 'soin': 895,\n",
       " 'etaistu': 896,\n",
       " 'prenons': 897,\n",
       " 'etudiant': 898,\n",
       " 'bruit': 899,\n",
       " 'mit': 900,\n",
       " 'devant': 901,\n",
       " 'devrionsnous': 902,\n",
       " 'ouvre': 903,\n",
       " 'amuse': 904,\n",
       " 'las': 905,\n",
       " 'allume': 906,\n",
       " 'cassee': 907,\n",
       " 'noir': 908,\n",
       " 'garcons': 909,\n",
       " 'souci': 910,\n",
       " 'maniere': 911,\n",
       " 'unique': 912,\n",
       " 'perplexe': 913,\n",
       " 'responsable': 914,\n",
       " 'moimeme': 915,\n",
       " 'meilleure': 916,\n",
       " 'affaire': 917,\n",
       " 'endormi': 918,\n",
       " 'avions': 919,\n",
       " 'hors': 920,\n",
       " 'cher': 921,\n",
       " 'piege': 922,\n",
       " 'suivi': 923,\n",
       " 'lundi': 924,\n",
       " 'savons': 925,\n",
       " 'fiere': 926,\n",
       " 'surs': 927,\n",
       " 'noel': 928,\n",
       " 'ufs': 929,\n",
       " 'but': 930,\n",
       " 'derniere': 931,\n",
       " 'brule': 932,\n",
       " 'devriez': 933,\n",
       " 'couteau': 934,\n",
       " 'affaires': 935,\n",
       " 'magasin': 936,\n",
       " 'reposer': 937,\n",
       " 'crayon': 938,\n",
       " 'sortie': 939,\n",
       " 'seulement': 940,\n",
       " 'utile': 941,\n",
       " 'ouverte': 942,\n",
       " 'vacances': 943,\n",
       " 'doute': 944,\n",
       " 'soleil': 945,\n",
       " 'continuait': 946,\n",
       " 'papier': 947,\n",
       " 'parie': 948,\n",
       " 'vent': 949,\n",
       " 'trahi': 950,\n",
       " 'taije': 951,\n",
       " 'faible': 952,\n",
       " 'alles': 953,\n",
       " 'talent': 954,\n",
       " 'masseoir': 955,\n",
       " 'fil': 956,\n",
       " 'ecole': 957,\n",
       " 'ladedans': 958,\n",
       " 'forte': 959,\n",
       " 'portes': 960,\n",
       " 'fantastique': 961,\n",
       " 'honte': 962,\n",
       " 'sante': 963,\n",
       " 'ty': 964,\n",
       " 'vastu': 965,\n",
       " 'lu': 966,\n",
       " 'repondu': 967,\n",
       " 'ceuxci': 968,\n",
       " 'force': 969,\n",
       " 'chef': 970,\n",
       " 'naif': 971,\n",
       " 'etrange': 972,\n",
       " 'hommes': 973,\n",
       " 'paix': 974,\n",
       " 'excuse': 975,\n",
       " 'prudents': 976,\n",
       " 'poids': 977,\n",
       " 'font': 978,\n",
       " 'pantalon': 979,\n",
       " 'vol': 980,\n",
       " 'attentivement': 981,\n",
       " 'aimons': 982,\n",
       " 'voler': 983,\n",
       " 'mensonge': 984,\n",
       " 'soucie': 985,\n",
       " 'appareil': 986,\n",
       " 'patient': 987,\n",
       " 'semblait': 988,\n",
       " 'voyager': 989,\n",
       " 'dure': 990,\n",
       " 'tombee': 991,\n",
       " 'blessee': 992,\n",
       " 'boisson': 993,\n",
       " 'coupable': 994,\n",
       " 'avonsnous': 995,\n",
       " 'sucre': 996,\n",
       " 'trompe': 997,\n",
       " 'doisje': 998,\n",
       " 'tant': 999,\n",
       " 'tas': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word index of French tokenizer\n",
    "fre_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the training data\n",
    "trainX = encode_sequences(fre_tokenizer, fre_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "\n",
    "# preparing the validation data\n",
    "validX = encode_sequences(fre_tokenizer, fre_length, valid[:, 1])\n",
    "validY = encode_sequences(eng_tokenizer, eng_length, valid[:, 0])\n",
    "validY = encode_output(validY, eng_vocab_size)\n",
    "\n",
    "# preparing testing data\n",
    "testX = encode_sequences(fre_tokenizer, fre_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Both Encoder GRU and Decoder GRU cell\n",
    "def both_gru(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "\tmodel.add(GRU(n_units))\n",
    "\tmodel.add(RepeatVector(tar_timesteps))\n",
    "\tmodel.add(GRU(n_units,return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "learning_rate = 1e-2\n",
    "both_gru = both_gru(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "both_gru.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 14, 256)           3119104   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 7, 256)            394752    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 7, 6010)           1544570   \n",
      "=================================================================\n",
      "Total params: 5,453,178\n",
      "Trainable params: 5,453,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/30\n",
      "547/547 - 103s - loss: 3.1634 - categorical_accuracy: 0.5458 - val_loss: 2.6934 - val_categorical_accuracy: 0.5970\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.69342, saving model to both_gru.h5\n",
      "Epoch 2/30\n",
      "547/547 - 79s - loss: 2.4113 - categorical_accuracy: 0.6183 - val_loss: 2.3372 - val_categorical_accuracy: 0.6306\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.69342 to 2.33721, saving model to both_gru.h5\n",
      "Epoch 3/30\n",
      "547/547 - 79s - loss: 2.0451 - categorical_accuracy: 0.6465 - val_loss: 2.1502 - val_categorical_accuracy: 0.6460\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.33721 to 2.15018, saving model to both_gru.h5\n",
      "Epoch 4/30\n",
      "547/547 - 80s - loss: 1.8027 - categorical_accuracy: 0.6637 - val_loss: 2.0458 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.15018 to 2.04577, saving model to both_gru.h5\n",
      "Epoch 5/30\n",
      "547/547 - 79s - loss: 1.6396 - categorical_accuracy: 0.6778 - val_loss: 1.9926 - val_categorical_accuracy: 0.6622\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.04577 to 1.99263, saving model to both_gru.h5\n",
      "Epoch 6/30\n",
      "547/547 - 79s - loss: 1.5251 - categorical_accuracy: 0.6864 - val_loss: 1.9646 - val_categorical_accuracy: 0.6671\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.99263 to 1.96456, saving model to both_gru.h5\n",
      "Epoch 7/30\n",
      "547/547 - 83s - loss: 1.4260 - categorical_accuracy: 0.6975 - val_loss: 1.9587 - val_categorical_accuracy: 0.6569\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.96456 to 1.95869, saving model to both_gru.h5\n",
      "Epoch 8/30\n",
      "547/547 - 81s - loss: 1.3570 - categorical_accuracy: 0.7055 - val_loss: 1.9324 - val_categorical_accuracy: 0.6739\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.95869 to 1.93239, saving model to both_gru.h5\n",
      "Epoch 9/30\n",
      "547/547 - 80s - loss: 1.2998 - categorical_accuracy: 0.7129 - val_loss: 1.9095 - val_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.93239 to 1.90946, saving model to both_gru.h5\n",
      "Epoch 10/30\n",
      "547/547 - 75s - loss: 1.2553 - categorical_accuracy: 0.7186 - val_loss: 1.9070 - val_categorical_accuracy: 0.6716\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.90946 to 1.90695, saving model to both_gru.h5\n",
      "Epoch 11/30\n",
      "547/547 - 81s - loss: 1.2114 - categorical_accuracy: 0.7246 - val_loss: 1.9170 - val_categorical_accuracy: 0.6759\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.90695\n",
      "Epoch 12/30\n",
      "547/547 - 78s - loss: 1.1777 - categorical_accuracy: 0.7292 - val_loss: 1.9071 - val_categorical_accuracy: 0.6749\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.90695\n",
      "Epoch 13/30\n",
      "547/547 - 79s - loss: 1.1483 - categorical_accuracy: 0.7336 - val_loss: 1.9061 - val_categorical_accuracy: 0.6799\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.90695 to 1.90605, saving model to both_gru.h5\n",
      "Epoch 14/30\n",
      "547/547 - 78s - loss: 1.1177 - categorical_accuracy: 0.7389 - val_loss: 1.8953 - val_categorical_accuracy: 0.6782\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.90605 to 1.89532, saving model to both_gru.h5\n",
      "Epoch 15/30\n",
      "547/547 - 85s - loss: 1.1016 - categorical_accuracy: 0.7409 - val_loss: 1.9378 - val_categorical_accuracy: 0.6776\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.89532\n",
      "Epoch 16/30\n",
      "547/547 - 80s - loss: 1.0892 - categorical_accuracy: 0.7441 - val_loss: 1.9097 - val_categorical_accuracy: 0.6793\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.89532\n",
      "Epoch 17/30\n",
      "547/547 - 81s - loss: 1.0697 - categorical_accuracy: 0.7451 - val_loss: 1.9201 - val_categorical_accuracy: 0.6845\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.89532\n",
      "Epoch 18/30\n",
      "547/547 - 82s - loss: 1.0496 - categorical_accuracy: 0.7491 - val_loss: 1.9154 - val_categorical_accuracy: 0.6810\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.89532\n",
      "Epoch 19/30\n",
      "547/547 - 77s - loss: 1.0414 - categorical_accuracy: 0.7496 - val_loss: 1.9381 - val_categorical_accuracy: 0.6826\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.89532\n",
      "Epoch 20/30\n",
      "547/547 - 81s - loss: 1.0391 - categorical_accuracy: 0.7501 - val_loss: 1.9327 - val_categorical_accuracy: 0.6765\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.89532\n",
      "Epoch 21/30\n",
      "547/547 - 81s - loss: 1.0377 - categorical_accuracy: 0.7504 - val_loss: 1.9421 - val_categorical_accuracy: 0.6779\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.89532\n",
      "Epoch 22/30\n",
      "547/547 - 79s - loss: 1.0242 - categorical_accuracy: 0.7525 - val_loss: 1.9532 - val_categorical_accuracy: 0.6784\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.89532\n",
      "Epoch 23/30\n",
      "547/547 - 80s - loss: 1.0192 - categorical_accuracy: 0.7532 - val_loss: 1.9574 - val_categorical_accuracy: 0.6796\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.89532\n",
      "Epoch 24/30\n",
      "547/547 - 82s - loss: 1.0079 - categorical_accuracy: 0.7552 - val_loss: 1.9537 - val_categorical_accuracy: 0.6808\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.89532\n",
      "Epoch 25/30\n",
      "547/547 - 81s - loss: 1.0102 - categorical_accuracy: 0.7552 - val_loss: 1.9824 - val_categorical_accuracy: 0.6778\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.89532\n",
      "Epoch 26/30\n",
      "547/547 - 83s - loss: 1.0077 - categorical_accuracy: 0.7553 - val_loss: 1.9569 - val_categorical_accuracy: 0.6813\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.89532\n",
      "Epoch 27/30\n",
      "547/547 - 78s - loss: 0.9973 - categorical_accuracy: 0.7564 - val_loss: 1.9589 - val_categorical_accuracy: 0.6796\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.89532\n",
      "Epoch 28/30\n",
      "547/547 - 80s - loss: 0.9913 - categorical_accuracy: 0.7574 - val_loss: 1.9955 - val_categorical_accuracy: 0.6799\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.89532\n",
      "Epoch 29/30\n",
      "547/547 - 80s - loss: 0.9941 - categorical_accuracy: 0.7566 - val_loss: 2.0024 - val_categorical_accuracy: 0.6792\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.89532\n",
      "Epoch 30/30\n",
      "547/547 - 74s - loss: 0.9967 - categorical_accuracy: 0.7569 - val_loss: 2.0156 - val_categorical_accuracy: 0.6778\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.89532\n"
     ]
    }
   ],
   "source": [
    "# summarize defined model\n",
    "print(both_gru.summary())\n",
    "plot_model(both_gru, to_file='gru_model.png', show_shapes=True)\n",
    "# fit model\n",
    "filename = 'both_gru.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history_both_gru = both_gru.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(validX, validY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  categorical_accuracy  val_loss  val_categorical_accuracy\n",
      "0   3.163437              0.545771  2.693422                  0.597029\n",
      "1   2.411328              0.618302  2.337207                  0.630629\n",
      "2   2.045118              0.646539  2.150177                  0.645971\n",
      "3   1.802673              0.663731  2.045769                  0.653343\n",
      "4   1.639592              0.677837  1.992630                  0.662200\n",
      "5   1.525113              0.686392  1.964557                  0.667086\n",
      "6   1.426029              0.697498  1.958693                  0.656943\n",
      "7   1.356985              0.705510  1.932390                  0.673886\n",
      "8   1.299796              0.712890  1.909459                  0.671943\n",
      "9   1.255346              0.718588  1.906954                  0.671571\n",
      "10  1.211441              0.724588  1.917022                  0.675886\n",
      "11  1.177698              0.729151  1.907092                  0.674914\n",
      "12  1.148300              0.733567  1.906054                  0.679914\n",
      "13  1.117732              0.738898  1.895323                  0.678229\n",
      "14  1.101627              0.740853  1.937769                  0.677571\n",
      "15  1.089182              0.744073  1.909741                  0.679314\n",
      "16  1.069681              0.745147  1.920060                  0.684514\n",
      "17  1.049622              0.749122  1.915354                  0.680971\n",
      "18  1.041361              0.749596  1.938127                  0.682629\n",
      "19  1.039117              0.750143  1.932749                  0.676514\n",
      "20  1.037737              0.750433  1.942057                  0.677857\n",
      "21  1.024218              0.752498  1.953182                  0.678371\n",
      "22  1.019224              0.753233  1.957435                  0.679600\n",
      "23  1.007933              0.755188  1.953674                  0.680800\n",
      "24  1.010193              0.755159  1.982367                  0.677800\n",
      "25  1.007704              0.755273  1.956869                  0.681343\n",
      "26  0.997308              0.756371  1.958876                  0.679571\n",
      "27  0.991344              0.757437  1.995496                  0.679943\n",
      "28  0.994129              0.756600  2.002417                  0.679200\n",
      "29  0.996743              0.756898  2.015648                  0.677829\n"
     ]
    }
   ],
   "source": [
    "df_history_both_gru = pd.DataFrame(history_both_gru.history)\n",
    "df_history_both_gru.to_csv('df_history_both_gru.csv')\n",
    "print(df_history_both_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "French(Source) : jai debranche la tele\n",
      "Target : i unplugged the tv\n",
      "Predicted : i unplugged the tv \n",
      "\n",
      "French(Source) : je suis desolee davoir dit cela\n",
      "Target : im sorry i said that\n",
      "Predicted : im sorry i said that \n",
      "\n",
      "French(Source) : jenfilai une chemise blanche\n",
      "Target : i wore a white shirt\n",
      "Predicted : i i a a pants \n",
      "\n",
      "French(Source) : il etait hors dhaleine\n",
      "Target : he was out of breath\n",
      "Predicted : it was in race \n",
      "\n",
      "French(Source) : cest un jour venteux\n",
      "Target : its a windy day\n",
      "Predicted : its a windy day \n",
      "\n",
      "French(Source) : je suis assez content\n",
      "Target : im happy enough\n",
      "Predicted : im too with \n",
      "\n",
      "French(Source) : amusonsnous\n",
      "Target : lets have fun\n",
      "Predicted : lets have fun \n",
      "\n",
      "French(Source) : questce qui vous trouble\n",
      "Target : whats troubling you\n",
      "Predicted : what troubling you \n",
      "\n",
      "French(Source) : cest impossible\n",
      "Target : its impossible\n",
      "Predicted : thats impossible \n",
      "\n",
      "French(Source) : personne ne change jamais\n",
      "Target : no one ever changes\n",
      "Predicted : no one changes \n",
      "\n",
      "French(Source) : ecoutetoi parler\n",
      "Target : listen to yourself\n",
      "Predicted : write to \n",
      "\n",
      "French(Source) : je suis gave\n",
      "Target : im stuffed\n",
      "Predicted : im lucky \n",
      "\n",
      "French(Source) : cest jour pluvieux\n",
      "Target : its a rainy day\n",
      "Predicted : its is rainy \n",
      "\n",
      "French(Source) : ca a lair cher\n",
      "Target : that looks expensive\n",
      "Predicted : that sounds expensive \n",
      "\n",
      "French(Source) : je me suis reveille a\n",
      "Target : i woke up at\n",
      "Predicted : i got on \n",
      "\n",
      "French(Source) : combien de temps aije sommeille\n",
      "Target : how long did i sleep\n",
      "Predicted : how me i i want \n",
      "\n",
      "French(Source) : essaie de ne pas paniquer\n",
      "Target : try not to panic\n",
      "Predicted : try not to panic \n",
      "\n",
      "French(Source) : je fermai mon parapluie\n",
      "Target : i closed my umbrella\n",
      "Predicted : i lost my umbrella \n",
      "\n",
      "French(Source) : cest toi le prisonnier\n",
      "Target : youre the prisoner\n",
      "Predicted : the the prisoner \n",
      "\n",
      "French(Source) : tom a une grande bouche\n",
      "Target : tom has a big mouth\n",
      "Predicted : tom has a dog mouth \n",
      "\n",
      "French(Source) : nous sommes tout a fait seules\n",
      "Target : were quite alone\n",
      "Predicted : we almost alone \n",
      "\n",
      "French(Source) : je dois trouver ca\n",
      "Target : i have to find that\n",
      "Predicted : i owe to handle that \n",
      "\n",
      "French(Source) : estce que tom vous connait\n",
      "Target : does tom know you\n",
      "Predicted : does tom know \n",
      "\n",
      "French(Source) : que peuventils faire\n",
      "Target : what can they do\n",
      "Predicted : what do do do \n",
      "\n",
      "French(Source) : personne ne vient\n",
      "Target : no one is coming\n",
      "Predicted : nobody one is \n",
      "\n",
      "French(Source) : tu sais que je taime\n",
      "Target : you know i love you\n",
      "Predicted : i know speak you you \n",
      "\n",
      "French(Source) : tu es fiable\n",
      "Target : youre trustworthy\n",
      "Predicted : youre trustworthy \n",
      "\n",
      "French(Source) : cest chouette\n",
      "Target : this is nice\n",
      "Predicted : thats is rest \n",
      "\n",
      "French(Source) : arretezvous ou vous etes\n",
      "Target : stop where you are\n",
      "Predicted : where you you \n",
      "\n",
      "French(Source) : lecole est finie\n",
      "Target : school is over\n",
      "Predicted : schools is \n",
      "\n",
      "French(Source) : je netais pas prepare\n",
      "Target : i was unprepared\n",
      "Predicted : i wasnt unprepared \n",
      "\n",
      "French(Source) : nous sommes seules\n",
      "Target : were alone\n",
      "Predicted : were diplomatic \n",
      "\n",
      "French(Source) : je vais te la preter\n",
      "Target : ill lend it to you\n",
      "Predicted : ill will you to you \n",
      "\n",
      "French(Source) : je pense que tes dingue\n",
      "Target : i think youre nuts\n",
      "Predicted : i think youre nuts \n",
      "\n",
      "French(Source) : cest ce a quoi nous nous attendions\n",
      "Target : its what we expected\n",
      "Predicted : its what you expect us \n",
      "\n",
      "French(Source) : tom continuait a parler\n",
      "Target : tom kept talking\n",
      "Predicted : tom kept talking \n",
      "\n",
      "French(Source) : jai de serieux doutes\n",
      "Target : i have serious doubts\n",
      "Predicted : i have lucky doubts \n",
      "\n",
      "French(Source) : nous avons de la compagnie\n",
      "Target : weve got company\n",
      "Predicted : we have company \n",
      "\n",
      "French(Source) : arretezvous juste la\n",
      "Target : stop right there\n",
      "Predicted : just right tom \n",
      "\n",
      "French(Source) : tom fait ses bagages\n",
      "Target : toms packing\n",
      "Predicted : tom packing packing \n",
      "\n",
      "French(Source) : je fais de mon mieux\n",
      "Target : im doing my best\n",
      "Predicted : ill keep my best \n",
      "\n",
      "French(Source) : tom aimetil son travail\n",
      "Target : does tom like his job\n",
      "Predicted : tom tom know his work \n",
      "\n",
      "French(Source) : on ma tendu un piege\n",
      "Target : i was framed\n",
      "Predicted : i got a lot \n",
      "\n",
      "French(Source) : sagitil dun cancer\n",
      "Target : is it cancer\n",
      "Predicted : is it a date \n",
      "\n",
      "French(Source) : nous avons ete tres prudents\n",
      "Target : we were very careful\n",
      "Predicted : we were very careful \n",
      "\n",
      "French(Source) : il prit un jour de conge\n",
      "Target : he took a day off\n",
      "Predicted : he drew a a \n",
      "\n",
      "French(Source) : fais une pause\n",
      "Target : take a breather\n",
      "Predicted : take a sec \n",
      "\n",
      "French(Source) : questce que cest\n",
      "Target : what is it\n",
      "Predicted : how are \n",
      "\n",
      "French(Source) : aideznous tom\n",
      "Target : help us tom\n",
      "Predicted : lets tom tom \n",
      "\n",
      "French(Source) : vous vous etes fait avoir\n",
      "Target : youve been had\n",
      "Predicted : youve had have \n",
      "\n",
      "BLEU-1: 0.601362\n",
      "BLEU-2: 0.454841\n",
      "BLEU-3: 0.378729\n",
      "BLEU-4: 0.229229\n",
      "test\n",
      "French(Source) : la pendule sarreta\n",
      "Target : the clock stopped\n",
      "Predicted : the cliches blew \n",
      "\n",
      "French(Source) : elles grandiront\n",
      "Target : theyll grow\n",
      "Predicted : theyll cheered \n",
      "\n",
      "French(Source) : vous etes tous heureux\n",
      "Target : youre all happy\n",
      "Predicted : youre all all \n",
      "\n",
      "French(Source) : je dors comme une pierre\n",
      "Target : im a sound sleeper\n",
      "Predicted : i have a of \n",
      "\n",
      "French(Source) : noussommestousretraites\n",
      "Target : were all retired\n",
      "Predicted : lets in \n",
      "\n",
      "French(Source) : celuila estil a vendre\n",
      "Target : is that one for sale\n",
      "Predicted : is he a a \n",
      "\n",
      "French(Source) : les hommes se rendent au travail\n",
      "Target : the men go to work\n",
      "Predicted : the lights on trees \n",
      "\n",
      "French(Source) : jai deux neveux\n",
      "Target : i have two nephews\n",
      "Predicted : i ate two two \n",
      "\n",
      "French(Source) : ma sur pleure souvent\n",
      "Target : my sister often cries\n",
      "Predicted : my me was a done \n",
      "\n",
      "French(Source) : cest simple\n",
      "Target : thats simple\n",
      "Predicted : its is \n",
      "\n",
      "French(Source) : tom adorait ca\n",
      "Target : tom loved it\n",
      "Predicted : tom tom tom that \n",
      "\n",
      "French(Source) : ca serait tres bien\n",
      "Target : that would be fine\n",
      "Predicted : you really very very \n",
      "\n",
      "French(Source) : etesvous jalouses\n",
      "Target : are you jealous\n",
      "Predicted : are you envious \n",
      "\n",
      "French(Source) : les huskies sont sympathiques\n",
      "Target : huskies are friendly\n",
      "Predicted : the lights appeared \n",
      "\n",
      "French(Source) : regarde ou tu poses le pied\n",
      "Target : watch your step\n",
      "Predicted : whens flip the go \n",
      "\n",
      "French(Source) : merci detre venu\n",
      "Target : thanks for coming\n",
      "Predicted : thank you coming \n",
      "\n",
      "French(Source) : ta migraine est passee\n",
      "Target : is your headache gone\n",
      "Predicted : toms is is \n",
      "\n",
      "French(Source) : je suis parfaitement heureux\n",
      "Target : im perfectly happy\n",
      "Predicted : im sure happy \n",
      "\n",
      "French(Source) : personne ne peut marreter\n",
      "Target : no one can stop me\n",
      "Predicted : no can can you \n",
      "\n",
      "French(Source) : jaime ma maman\n",
      "Target : i love my mom\n",
      "Predicted : i like to horse \n",
      "\n",
      "French(Source) : sortez si vous pouvez\n",
      "Target : get out if you can\n",
      "Predicted : come me to you when \n",
      "\n",
      "French(Source) : verifie ton chapeau\n",
      "Target : check your hat\n",
      "Predicted : bring your hat hat \n",
      "\n",
      "French(Source) : tom dessine bien\n",
      "Target : tom draws well\n",
      "Predicted : tom is \n",
      "\n",
      "French(Source) : thomas avertit marie\n",
      "Target : tom warned mary\n",
      "Predicted : tom tom mary \n",
      "\n",
      "French(Source) : je pensais que vous seriez daccord\n",
      "Target : i thought youd agree\n",
      "Predicted : i thought i agree you you \n",
      "\n",
      "French(Source) : recrutestu\n",
      "Target : are you hiring\n",
      "Predicted : lets working \n",
      "\n",
      "French(Source) : je me bats mal\n",
      "Target : i fight badly\n",
      "Predicted : i feel hurt \n",
      "\n",
      "French(Source) : suisje soupconne\n",
      "Target : am i under suspicion\n",
      "Predicted : am i pretty \n",
      "\n",
      "French(Source) : pourquoi tom atil ete tue\n",
      "Target : why was tom killed\n",
      "Predicted : why was tom \n",
      "\n",
      "French(Source) : je sais que tom est lent\n",
      "Target : i know tom is slow\n",
      "Predicted : i know tom is is \n",
      "\n",
      "French(Source) : vous aurez besoin de ceci\n",
      "Target : youll need this\n",
      "Predicted : you needed to \n",
      "\n",
      "French(Source) : laissezle seul\n",
      "Target : leave him alone\n",
      "Predicted : sign here \n",
      "\n",
      "French(Source) : je vous avais prevenue\n",
      "Target : i did warn you\n",
      "Predicted : i warned you \n",
      "\n",
      "French(Source) : allons dans ta chambre\n",
      "Target : lets go to your room\n",
      "Predicted : lets take your time \n",
      "\n",
      "French(Source) : je me suis levee il y a une heure\n",
      "Target : i got up an hour ago\n",
      "Predicted : i awoke a hour hour \n",
      "\n",
      "French(Source) : il faut que je dorme\n",
      "Target : i have to sleep\n",
      "Predicted : i have to go \n",
      "\n",
      "French(Source) : je me suis senti exclue\n",
      "Target : i felt left out\n",
      "Predicted : i felt responsible \n",
      "\n",
      "French(Source) : je reviens\n",
      "Target : ill come back\n",
      "Predicted : ill be \n",
      "\n",
      "French(Source) : nayez pas lair si choquees\n",
      "Target : dont look so shocked\n",
      "Predicted : dont be so rude \n",
      "\n",
      "French(Source) : elle na pas peur\n",
      "Target : she has no fear\n",
      "Predicted : she is scared true \n",
      "\n",
      "French(Source) : je ne suis plus fatigue\n",
      "Target : im no longer tired\n",
      "Predicted : im not tired \n",
      "\n",
      "French(Source) : je deteste les longs au revoir\n",
      "Target : i hate long goodbyes\n",
      "Predicted : i hate you \n",
      "\n",
      "French(Source) : sortez\n",
      "Target : get out\n",
      "Predicted : get out \n",
      "\n",
      "French(Source) : tom fit un pas en avant\n",
      "Target : tom stepped forward\n",
      "Predicted : tom was lots a \n",
      "\n",
      "French(Source) : il est en train de vous regarder\n",
      "Target : hes looking at you\n",
      "Predicted : hes is to are \n",
      "\n",
      "French(Source) : pars demain\n",
      "Target : leave tomorrow\n",
      "Predicted : go tomorrow tomorrow \n",
      "\n",
      "French(Source) : je vous ai deja paye\n",
      "Target : ive already paid you\n",
      "Predicted : i paid paid that \n",
      "\n",
      "French(Source) : elle laca ses chaussures\n",
      "Target : she laced her shoes\n",
      "Predicted : she reserved his hat \n",
      "\n",
      "French(Source) : il ny a pas le feu au lac\n",
      "Target : there is no hurry\n",
      "Predicted : theres gets in the word \n",
      "\n",
      "French(Source) : jai deux tickets\n",
      "Target : i have two tickets\n",
      "Predicted : i cried two chips \n",
      "\n",
      "BLEU-1: 0.469178\n",
      "BLEU-2: 0.315791\n",
      "BLEU-3: 0.246792\n",
      "BLEU-4: 0.129878\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "both_gru = load_model('both_gru.h5')\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "bleu_train_both_gru = evaluate_model(both_gru, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "bleu_test_both_gru = evaluate_model(both_gru, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Both Encoder LSTM and Decoder LSTM cell\n",
    "def both_lstm(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "\tlearning_rate = 1e-2\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "\tmodel.add(LSTM(n_units))\n",
    "\tmodel.add(RepeatVector(tar_timesteps))\n",
    "\tmodel.add(LSTM(n_units,return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "learning_rate = 1e-2\n",
    "both_lstm = both_lstm(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "both_lstm.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 14, 256)           3119104   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 6010)           1544570   \n",
      "=================================================================\n",
      "Total params: 5,714,298\n",
      "Trainable params: 5,714,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/30\n",
      "547/547 - 97s - loss: 3.2524 - categorical_accuracy: 0.5351 - val_loss: 2.7659 - val_categorical_accuracy: 0.5751\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.76587, saving model to both_lstm.h5\n",
      "Epoch 2/30\n",
      "547/547 - 85s - loss: 2.4974 - categorical_accuracy: 0.6011 - val_loss: 2.4475 - val_categorical_accuracy: 0.6139\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.76587 to 2.44752, saving model to both_lstm.h5\n",
      "Epoch 3/30\n",
      "547/547 - 91s - loss: 2.1231 - categorical_accuracy: 0.6366 - val_loss: 2.2079 - val_categorical_accuracy: 0.6414\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.44752 to 2.20790, saving model to both_lstm.h5\n",
      "Epoch 4/30\n",
      "547/547 - 92s - loss: 1.8504 - categorical_accuracy: 0.6610 - val_loss: 2.0892 - val_categorical_accuracy: 0.6514\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.20790 to 2.08922, saving model to both_lstm.h5\n",
      "Epoch 5/30\n",
      "547/547 - 92s - loss: 1.6310 - categorical_accuracy: 0.6815 - val_loss: 2.0067 - val_categorical_accuracy: 0.6629\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.08922 to 2.00667, saving model to both_lstm.h5\n",
      "Epoch 6/30\n",
      "547/547 - 94s - loss: 1.4570 - categorical_accuracy: 0.6995 - val_loss: 1.9701 - val_categorical_accuracy: 0.6684\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.00667 to 1.97006, saving model to both_lstm.h5\n",
      "Epoch 7/30\n",
      "547/547 - 88s - loss: 1.3374 - categorical_accuracy: 0.7129 - val_loss: 1.9270 - val_categorical_accuracy: 0.6728\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.97006 to 1.92698, saving model to both_lstm.h5\n",
      "Epoch 8/30\n",
      "547/547 - 91s - loss: 1.2238 - categorical_accuracy: 0.7279 - val_loss: 1.9202 - val_categorical_accuracy: 0.6773\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.92698 to 1.92015, saving model to both_lstm.h5\n",
      "Epoch 9/30\n",
      "547/547 - 90s - loss: 1.1423 - categorical_accuracy: 0.7392 - val_loss: 1.9187 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.92015 to 1.91865, saving model to both_lstm.h5\n",
      "Epoch 10/30\n",
      "547/547 - 92s - loss: 1.0734 - categorical_accuracy: 0.7503 - val_loss: 1.9110 - val_categorical_accuracy: 0.6806\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.91865 to 1.91103, saving model to both_lstm.h5\n",
      "Epoch 11/30\n",
      "547/547 - 91s - loss: 1.0120 - categorical_accuracy: 0.7600 - val_loss: 1.9205 - val_categorical_accuracy: 0.6808\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.91103\n",
      "Epoch 12/30\n",
      "547/547 - 92s - loss: 0.9603 - categorical_accuracy: 0.7691 - val_loss: 1.9287 - val_categorical_accuracy: 0.6772\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.91103\n",
      "Epoch 13/30\n",
      "547/547 - 89s - loss: 0.9228 - categorical_accuracy: 0.7755 - val_loss: 1.9297 - val_categorical_accuracy: 0.6834\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.91103\n",
      "Epoch 14/30\n",
      "547/547 - 90s - loss: 0.8883 - categorical_accuracy: 0.7813 - val_loss: 1.9361 - val_categorical_accuracy: 0.6831\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.91103\n",
      "Epoch 15/30\n",
      "547/547 - 90s - loss: 0.8721 - categorical_accuracy: 0.7845 - val_loss: 1.9508 - val_categorical_accuracy: 0.6815\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.91103\n",
      "Epoch 16/30\n",
      "547/547 - 91s - loss: 0.8473 - categorical_accuracy: 0.7881 - val_loss: 1.9723 - val_categorical_accuracy: 0.6871\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.91103\n",
      "Epoch 17/30\n",
      "547/547 - 90s - loss: 0.8202 - categorical_accuracy: 0.7929 - val_loss: 1.9650 - val_categorical_accuracy: 0.6855\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.91103\n",
      "Epoch 18/30\n",
      "547/547 - 90s - loss: 0.7947 - categorical_accuracy: 0.7973 - val_loss: 1.9900 - val_categorical_accuracy: 0.6817\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.91103\n",
      "Epoch 19/30\n",
      "547/547 - 90s - loss: 0.7777 - categorical_accuracy: 0.8015 - val_loss: 2.0068 - val_categorical_accuracy: 0.6831\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.91103\n",
      "Epoch 20/30\n",
      "547/547 - 89s - loss: 0.7753 - categorical_accuracy: 0.8016 - val_loss: 2.0171 - val_categorical_accuracy: 0.6811\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.91103\n",
      "Epoch 21/30\n",
      "547/547 - 87s - loss: 0.7915 - categorical_accuracy: 0.8003 - val_loss: 2.0276 - val_categorical_accuracy: 0.6832\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.91103\n",
      "Epoch 22/30\n",
      "547/547 - 87s - loss: 0.7743 - categorical_accuracy: 0.8028 - val_loss: 2.0345 - val_categorical_accuracy: 0.6820\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.91103\n",
      "Epoch 23/30\n",
      "547/547 - 94s - loss: 0.7544 - categorical_accuracy: 0.8071 - val_loss: 2.0275 - val_categorical_accuracy: 0.6836\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.91103\n",
      "Epoch 24/30\n",
      "547/547 - 94s - loss: 0.7412 - categorical_accuracy: 0.8092 - val_loss: 2.0671 - val_categorical_accuracy: 0.6845\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.91103\n",
      "Epoch 25/30\n",
      "547/547 - 95s - loss: 0.7450 - categorical_accuracy: 0.8086 - val_loss: 2.0933 - val_categorical_accuracy: 0.6801\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.91103\n",
      "Epoch 26/30\n",
      "547/547 - 97s - loss: 0.7549 - categorical_accuracy: 0.8060 - val_loss: 2.0774 - val_categorical_accuracy: 0.6844\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.91103\n",
      "Epoch 27/30\n",
      "547/547 - 94s - loss: 0.7336 - categorical_accuracy: 0.8112 - val_loss: 2.0799 - val_categorical_accuracy: 0.6831\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.91103\n",
      "Epoch 28/30\n",
      "547/547 - 95s - loss: 0.7270 - categorical_accuracy: 0.8116 - val_loss: 2.0954 - val_categorical_accuracy: 0.6802\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.91103\n",
      "Epoch 29/30\n",
      "547/547 - 97s - loss: 0.7203 - categorical_accuracy: 0.8134 - val_loss: 2.0990 - val_categorical_accuracy: 0.6814\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.91103\n",
      "Epoch 30/30\n",
      "547/547 - 89s - loss: 0.7064 - categorical_accuracy: 0.8150 - val_loss: 2.1090 - val_categorical_accuracy: 0.6832\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.91103\n"
     ]
    }
   ],
   "source": [
    "# summarize defined model\n",
    "print(both_lstm.summary())\n",
    "plot_model(both_lstm, to_file='both_lstm.png', show_shapes=True)\n",
    "# fit model\n",
    "filename = 'both_lstm.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history_both_lstm = both_lstm.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(validX, validY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history_both_lstm = pd.DataFrame(history_both_lstm.history)\n",
    "df_history_both_lstm\n",
    "df_history_both_lstm.to_csv('df_history_both_lstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "French(Source) : jai debranche la tele\n",
      "Target : i unplugged the tv\n",
      "Predicted : i unplugged the tv \n",
      "\n",
      "French(Source) : je suis desolee davoir dit cela\n",
      "Target : im sorry i said that\n",
      "Predicted : im sorry i said that \n",
      "\n",
      "French(Source) : jenfilai une chemise blanche\n",
      "Target : i wore a white shirt\n",
      "Predicted : i a a flat \n",
      "\n",
      "French(Source) : il etait hors dhaleine\n",
      "Target : he was out of breath\n",
      "Predicted : he was in a of \n",
      "\n",
      "French(Source) : cest un jour venteux\n",
      "Target : its a windy day\n",
      "Predicted : its a real \n",
      "\n",
      "French(Source) : je suis assez content\n",
      "Target : im happy enough\n",
      "Predicted : im happy happy \n",
      "\n",
      "French(Source) : amusonsnous\n",
      "Target : lets have fun\n",
      "Predicted : lets coming some \n",
      "\n",
      "French(Source) : questce qui vous trouble\n",
      "Target : whats troubling you\n",
      "Predicted : whats troubling you \n",
      "\n",
      "French(Source) : cest impossible\n",
      "Target : its impossible\n",
      "Predicted : thats is \n",
      "\n",
      "French(Source) : personne ne change jamais\n",
      "Target : no one ever changes\n",
      "Predicted : no one stopped \n",
      "\n",
      "French(Source) : ecoutetoi parler\n",
      "Target : listen to yourself\n",
      "Predicted : please vote \n",
      "\n",
      "French(Source) : je suis gave\n",
      "Target : im stuffed\n",
      "Predicted : im broke \n",
      "\n",
      "French(Source) : cest jour pluvieux\n",
      "Target : its a rainy day\n",
      "Predicted : this the day \n",
      "\n",
      "French(Source) : ca a lair cher\n",
      "Target : that looks expensive\n",
      "Predicted : it seems urgent \n",
      "\n",
      "French(Source) : je me suis reveille a\n",
      "Target : i woke up at\n",
      "Predicted : i woke my my \n",
      "\n",
      "French(Source) : combien de temps aije sommeille\n",
      "Target : how long did i sleep\n",
      "Predicted : how long did you take \n",
      "\n",
      "French(Source) : essaie de ne pas paniquer\n",
      "Target : try not to panic\n",
      "Predicted : try for for \n",
      "\n",
      "French(Source) : je fermai mon parapluie\n",
      "Target : i closed my umbrella\n",
      "Predicted : i have my roommate \n",
      "\n",
      "French(Source) : cest toi le prisonnier\n",
      "Target : youre the prisoner\n",
      "Predicted : youre the prisoner \n",
      "\n",
      "French(Source) : tom a une grande bouche\n",
      "Target : tom has a big mouth\n",
      "Predicted : tom has a big mouth \n",
      "\n",
      "French(Source) : nous sommes tout a fait seules\n",
      "Target : were quite alone\n",
      "Predicted : were quite alone \n",
      "\n",
      "French(Source) : je dois trouver ca\n",
      "Target : i have to find that\n",
      "Predicted : i must to this this \n",
      "\n",
      "French(Source) : estce que tom vous connait\n",
      "Target : does tom know you\n",
      "Predicted : did tom know \n",
      "\n",
      "French(Source) : que peuventils faire\n",
      "Target : what can they do\n",
      "Predicted : what can do do \n",
      "\n",
      "French(Source) : personne ne vient\n",
      "Target : no one is coming\n",
      "Predicted : no one was \n",
      "\n",
      "French(Source) : tu sais que je taime\n",
      "Target : you know i love you\n",
      "Predicted : i you you you you \n",
      "\n",
      "French(Source) : tu es fiable\n",
      "Target : youre trustworthy\n",
      "Predicted : youre disloyal \n",
      "\n",
      "French(Source) : cest chouette\n",
      "Target : this is nice\n",
      "Predicted : thats sweet sweet \n",
      "\n",
      "French(Source) : arretezvous ou vous etes\n",
      "Target : stop where you are\n",
      "Predicted : where are they \n",
      "\n",
      "French(Source) : lecole est finie\n",
      "Target : school is over\n",
      "Predicted : school is \n",
      "\n",
      "French(Source) : je netais pas prepare\n",
      "Target : i was unprepared\n",
      "Predicted : i wasnt unprepared \n",
      "\n",
      "French(Source) : nous sommes seules\n",
      "Target : were alone\n",
      "Predicted : were alone \n",
      "\n",
      "French(Source) : je vais te la preter\n",
      "Target : ill lend it to you\n",
      "Predicted : ill woke you jump you \n",
      "\n",
      "French(Source) : je pense que tes dingue\n",
      "Target : i think youre nuts\n",
      "Predicted : i think youre funny \n",
      "\n",
      "French(Source) : cest ce a quoi nous nous attendions\n",
      "Target : its what we expected\n",
      "Predicted : thats what it expected \n",
      "\n",
      "French(Source) : tom continuait a parler\n",
      "Target : tom kept talking\n",
      "Predicted : tom kept talking \n",
      "\n",
      "French(Source) : jai de serieux doutes\n",
      "Target : i have serious doubts\n",
      "Predicted : i had a doubts \n",
      "\n",
      "French(Source) : nous avons de la compagnie\n",
      "Target : weve got company\n",
      "Predicted : we were company \n",
      "\n",
      "French(Source) : arretezvous juste la\n",
      "Target : stop right there\n",
      "Predicted : come out there \n",
      "\n",
      "French(Source) : tom fait ses bagages\n",
      "Target : toms packing\n",
      "Predicted : tom packing packing \n",
      "\n",
      "French(Source) : je fais de mon mieux\n",
      "Target : im doing my best\n",
      "Predicted : ill doing my best \n",
      "\n",
      "French(Source) : tom aimetil son travail\n",
      "Target : does tom like his job\n",
      "Predicted : is tom love job job \n",
      "\n",
      "French(Source) : on ma tendu un piege\n",
      "Target : i was framed\n",
      "Predicted : i was framed trap \n",
      "\n",
      "French(Source) : sagitil dun cancer\n",
      "Target : is it cancer\n",
      "Predicted : is it annoy \n",
      "\n",
      "French(Source) : nous avons ete tres prudents\n",
      "Target : we were very careful\n",
      "Predicted : we were very worried \n",
      "\n",
      "French(Source) : il prit un jour de conge\n",
      "Target : he took a day off\n",
      "Predicted : he has a day \n",
      "\n",
      "French(Source) : fais une pause\n",
      "Target : take a breather\n",
      "Predicted : give a while \n",
      "\n",
      "French(Source) : questce que cest\n",
      "Target : what is it\n",
      "Predicted : what is \n",
      "\n",
      "French(Source) : aideznous tom\n",
      "Target : help us tom\n",
      "Predicted : try tom tom \n",
      "\n",
      "French(Source) : vous vous etes fait avoir\n",
      "Target : youve been had\n",
      "Predicted : youve been been \n",
      "\n",
      "BLEU-1: 0.620234\n",
      "BLEU-2: 0.476972\n",
      "BLEU-3: 0.401353\n",
      "BLEU-4: 0.250423\n",
      "test\n",
      "French(Source) : la pendule sarreta\n",
      "Target : the clock stopped\n",
      "Predicted : the is melting \n",
      "\n",
      "French(Source) : elles grandiront\n",
      "Target : theyll grow\n",
      "Predicted : they escaping \n",
      "\n",
      "French(Source) : vous etes tous heureux\n",
      "Target : youre all happy\n",
      "Predicted : youre happy happy \n",
      "\n",
      "French(Source) : je dors comme une pierre\n",
      "Target : im a sound sleeper\n",
      "Predicted : i do a a lake \n",
      "\n",
      "French(Source) : noussommestousretraites\n",
      "Target : were all retired\n",
      "Predicted : get it \n",
      "\n",
      "French(Source) : celuila estil a vendre\n",
      "Target : is that one for sale\n",
      "Predicted : can you to me \n",
      "\n",
      "French(Source) : les hommes se rendent au travail\n",
      "Target : the men go to work\n",
      "Predicted : utilities are on \n",
      "\n",
      "French(Source) : jai deux neveux\n",
      "Target : i have two nephews\n",
      "Predicted : i have a \n",
      "\n",
      "French(Source) : ma sur pleure souvent\n",
      "Target : my sister often cries\n",
      "Predicted : my sister is lot \n",
      "\n",
      "French(Source) : cest simple\n",
      "Target : thats simple\n",
      "Predicted : its true \n",
      "\n",
      "French(Source) : tom adorait ca\n",
      "Target : tom loved it\n",
      "Predicted : tom loved that that \n",
      "\n",
      "French(Source) : ca serait tres bien\n",
      "Target : that would be fine\n",
      "Predicted : that cant be good \n",
      "\n",
      "French(Source) : etesvous jalouses\n",
      "Target : are you jealous\n",
      "Predicted : are you jealous \n",
      "\n",
      "French(Source) : les huskies sont sympathiques\n",
      "Target : huskies are friendly\n",
      "Predicted : the are are \n",
      "\n",
      "French(Source) : regarde ou tu poses le pied\n",
      "Target : watch your step\n",
      "Predicted : please what for slower \n",
      "\n",
      "French(Source) : merci detre venu\n",
      "Target : thanks for coming\n",
      "Predicted : thank you one of \n",
      "\n",
      "French(Source) : ta migraine est passee\n",
      "Target : is your headache gone\n",
      "Predicted : your were is hard \n",
      "\n",
      "French(Source) : je suis parfaitement heureux\n",
      "Target : im perfectly happy\n",
      "Predicted : im happy happy \n",
      "\n",
      "French(Source) : personne ne peut marreter\n",
      "Target : no one can stop me\n",
      "Predicted : let me talk \n",
      "\n",
      "French(Source) : jaime ma maman\n",
      "Target : i love my mom\n",
      "Predicted : i like my new \n",
      "\n",
      "French(Source) : sortez si vous pouvez\n",
      "Target : get out if you can\n",
      "Predicted : get whatever if you you \n",
      "\n",
      "French(Source) : verifie ton chapeau\n",
      "Target : check your hat\n",
      "Predicted : remove on on hat \n",
      "\n",
      "French(Source) : tom dessine bien\n",
      "Target : tom draws well\n",
      "Predicted : tom is well \n",
      "\n",
      "French(Source) : thomas avertit marie\n",
      "Target : tom warned mary\n",
      "Predicted : youre has died \n",
      "\n",
      "French(Source) : je pensais que vous seriez daccord\n",
      "Target : i thought youd agree\n",
      "Predicted : i think you be \n",
      "\n",
      "French(Source) : recrutestu\n",
      "Target : are you hiring\n",
      "Predicted : lets it \n",
      "\n",
      "French(Source) : je me bats mal\n",
      "Target : i fight badly\n",
      "Predicted : i feel them \n",
      "\n",
      "French(Source) : suisje soupconne\n",
      "Target : am i under suspicion\n",
      "Predicted : am i hired \n",
      "\n",
      "French(Source) : pourquoi tom atil ete tue\n",
      "Target : why was tom killed\n",
      "Predicted : why did stars was \n",
      "\n",
      "French(Source) : je sais que tom est lent\n",
      "Target : i know tom is slow\n",
      "Predicted : i know tom is \n",
      "\n",
      "French(Source) : vous aurez besoin de ceci\n",
      "Target : youll need this\n",
      "Predicted : you need this this \n",
      "\n",
      "French(Source) : laissezle seul\n",
      "Target : leave him alone\n",
      "Predicted : let it \n",
      "\n",
      "French(Source) : je vous avais prevenue\n",
      "Target : i did warn you\n",
      "Predicted : i made you warned \n",
      "\n",
      "French(Source) : allons dans ta chambre\n",
      "Target : lets go to your room\n",
      "Predicted : lets call your room \n",
      "\n",
      "French(Source) : je me suis levee il y a une heure\n",
      "Target : i got up an hour ago\n",
      "Predicted : i prefer to a game \n",
      "\n",
      "French(Source) : il faut que je dorme\n",
      "Target : i have to sleep\n",
      "Predicted : i need i miss to \n",
      "\n",
      "French(Source) : je me suis senti exclue\n",
      "Target : i felt left out\n",
      "Predicted : i had lost \n",
      "\n",
      "French(Source) : je reviens\n",
      "Target : ill come back\n",
      "Predicted : ill wait \n",
      "\n",
      "French(Source) : nayez pas lair si choquees\n",
      "Target : dont look so shocked\n",
      "Predicted : dont were so too \n",
      "\n",
      "French(Source) : elle na pas peur\n",
      "Target : she has no fear\n",
      "Predicted : she isnt scared \n",
      "\n",
      "French(Source) : je ne suis plus fatigue\n",
      "Target : im no longer tired\n",
      "Predicted : im am tired \n",
      "\n",
      "French(Source) : je deteste les longs au revoir\n",
      "Target : i hate long goodbyes\n",
      "Predicted : i hate my parents \n",
      "\n",
      "French(Source) : sortez\n",
      "Target : get out\n",
      "Predicted : get out \n",
      "\n",
      "French(Source) : tom fit un pas en avant\n",
      "Target : tom stepped forward\n",
      "Predicted : tom made a \n",
      "\n",
      "French(Source) : il est en train de vous regarder\n",
      "Target : hes looking at you\n",
      "Predicted : he looking at \n",
      "\n",
      "French(Source) : pars demain\n",
      "Target : leave tomorrow\n",
      "Predicted : the do \n",
      "\n",
      "French(Source) : je vous ai deja paye\n",
      "Target : ive already paid you\n",
      "Predicted : i woke you i \n",
      "\n",
      "French(Source) : elle laca ses chaussures\n",
      "Target : she laced her shoes\n",
      "Predicted : she is his shoes \n",
      "\n",
      "French(Source) : il ny a pas le feu au lac\n",
      "Target : there is no hurry\n",
      "Predicted : there no the the \n",
      "\n",
      "French(Source) : jai deux tickets\n",
      "Target : i have two tickets\n",
      "Predicted : i have a \n",
      "\n",
      "BLEU-1: 0.459235\n",
      "BLEU-2: 0.305159\n",
      "BLEU-3: 0.236943\n",
      "BLEU-4: 0.123820\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "both_lstm = load_model('both_lstm.h5')\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "bleu_train_both_lstm = evaluate_model(both_lstm, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "bleu_test_both_lstm = evaluate_model(both_lstm, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3:  Encoder GRU and Decoder LSTM cell\n",
    "\n",
    "def gru_lstm(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "\tlearning_rate = 1e-2\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "\tmodel.add(GRU(n_units))\n",
    "\tmodel.add(RepeatVector(tar_timesteps))\n",
    "\tmodel.add(LSTM(n_units,return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "learning_rate = 1e-2\n",
    "gru_lstm = gru_lstm(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "gru_lstm.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 14, 256)           3119104   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               394752    \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 7, 6010)           1544570   \n",
      "=================================================================\n",
      "Total params: 5,583,738\n",
      "Trainable params: 5,583,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/30\n",
      "547/547 - 93s - loss: 3.1241 - categorical_accuracy: 0.5505 - val_loss: 2.6033 - val_categorical_accuracy: 0.5971\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.60333, saving model to gru_lstm.h5\n",
      "Epoch 2/30\n",
      "547/547 - 88s - loss: 2.3329 - categorical_accuracy: 0.6212 - val_loss: 2.2692 - val_categorical_accuracy: 0.6347\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.60333 to 2.26924, saving model to gru_lstm.h5\n",
      "Epoch 3/30\n",
      "547/547 - 88s - loss: 1.9669 - categorical_accuracy: 0.6530 - val_loss: 2.0902 - val_categorical_accuracy: 0.6492\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.26924 to 2.09020, saving model to gru_lstm.h5\n",
      "Epoch 4/30\n",
      "547/547 - 86s - loss: 1.7278 - categorical_accuracy: 0.6726 - val_loss: 1.9820 - val_categorical_accuracy: 0.6610\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.09020 to 1.98197, saving model to gru_lstm.h5\n",
      "Epoch 5/30\n",
      "547/547 - 84s - loss: 1.5497 - categorical_accuracy: 0.6888 - val_loss: 1.9027 - val_categorical_accuracy: 0.6722\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.98197 to 1.90272, saving model to gru_lstm.h5\n",
      "Epoch 6/30\n",
      "547/547 - 85s - loss: 1.4136 - categorical_accuracy: 0.7024 - val_loss: 1.8565 - val_categorical_accuracy: 0.6774\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.90272 to 1.85647, saving model to gru_lstm.h5\n",
      "Epoch 7/30\n",
      "547/547 - 88s - loss: 1.3055 - categorical_accuracy: 0.7150 - val_loss: 1.8317 - val_categorical_accuracy: 0.6813\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.85647 to 1.83170, saving model to gru_lstm.h5\n",
      "Epoch 8/30\n",
      "547/547 - 89s - loss: 1.2168 - categorical_accuracy: 0.7268 - val_loss: 1.8272 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.83170 to 1.82724, saving model to gru_lstm.h5\n",
      "Epoch 9/30\n",
      "547/547 - 88s - loss: 1.1511 - categorical_accuracy: 0.7354 - val_loss: 1.8208 - val_categorical_accuracy: 0.6843\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.82724 to 1.82081, saving model to gru_lstm.h5\n",
      "Epoch 10/30\n",
      "547/547 - 88s - loss: 1.0953 - categorical_accuracy: 0.7440 - val_loss: 1.8044 - val_categorical_accuracy: 0.6906\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.82081 to 1.80442, saving model to gru_lstm.h5\n",
      "Epoch 11/30\n",
      "547/547 - 89s - loss: 1.0584 - categorical_accuracy: 0.7491 - val_loss: 1.8278 - val_categorical_accuracy: 0.6893\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.80442\n",
      "Epoch 12/30\n",
      "547/547 - 87s - loss: 1.0293 - categorical_accuracy: 0.7535 - val_loss: 1.8179 - val_categorical_accuracy: 0.6891\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.80442\n",
      "Epoch 13/30\n",
      "547/547 - 89s - loss: 0.9994 - categorical_accuracy: 0.7583 - val_loss: 1.8251 - val_categorical_accuracy: 0.6914\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.80442\n",
      "Epoch 14/30\n",
      "547/547 - 87s - loss: 0.9741 - categorical_accuracy: 0.7628 - val_loss: 1.8296 - val_categorical_accuracy: 0.6909\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.80442\n",
      "Epoch 15/30\n",
      "547/547 - 88s - loss: 0.9578 - categorical_accuracy: 0.7645 - val_loss: 1.8334 - val_categorical_accuracy: 0.6910\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.80442\n",
      "Epoch 16/30\n",
      "547/547 - 85s - loss: 0.9352 - categorical_accuracy: 0.7681 - val_loss: 1.8370 - val_categorical_accuracy: 0.6930\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.80442\n",
      "Epoch 17/30\n",
      "547/547 - 86s - loss: 0.9183 - categorical_accuracy: 0.7708 - val_loss: 1.8497 - val_categorical_accuracy: 0.6928\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.80442\n",
      "Epoch 18/30\n",
      "547/547 - 86s - loss: 0.9024 - categorical_accuracy: 0.7744 - val_loss: 1.8580 - val_categorical_accuracy: 0.6921\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.80442\n",
      "Epoch 19/30\n",
      "547/547 - 85s - loss: 0.8903 - categorical_accuracy: 0.7759 - val_loss: 1.8775 - val_categorical_accuracy: 0.6950\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.80442\n",
      "Epoch 20/30\n",
      "547/547 - 92s - loss: 0.8874 - categorical_accuracy: 0.7753 - val_loss: 1.8619 - val_categorical_accuracy: 0.6975\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.80442\n",
      "Epoch 21/30\n",
      "547/547 - 90s - loss: 0.8603 - categorical_accuracy: 0.7824 - val_loss: 1.8789 - val_categorical_accuracy: 0.6940\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.80442\n",
      "Epoch 22/30\n",
      "547/547 - 87s - loss: 0.8508 - categorical_accuracy: 0.7825 - val_loss: 1.8800 - val_categorical_accuracy: 0.6919\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.80442\n",
      "Epoch 23/30\n",
      "547/547 - 89s - loss: 0.8570 - categorical_accuracy: 0.7806 - val_loss: 1.8915 - val_categorical_accuracy: 0.6926\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.80442\n",
      "Epoch 24/30\n",
      "547/547 - 88s - loss: 0.8628 - categorical_accuracy: 0.7797 - val_loss: 1.9009 - val_categorical_accuracy: 0.6893\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.80442\n",
      "Epoch 25/30\n",
      "547/547 - 89s - loss: 0.8475 - categorical_accuracy: 0.7818 - val_loss: 1.8926 - val_categorical_accuracy: 0.6917\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.80442\n",
      "Epoch 26/30\n",
      "547/547 - 88s - loss: 0.8342 - categorical_accuracy: 0.7849 - val_loss: 1.9092 - val_categorical_accuracy: 0.6901\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.80442\n",
      "Epoch 27/30\n",
      "547/547 - 85s - loss: 0.8322 - categorical_accuracy: 0.7859 - val_loss: 1.9270 - val_categorical_accuracy: 0.6913\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.80442\n",
      "Epoch 28/30\n",
      "547/547 - 95s - loss: 0.8258 - categorical_accuracy: 0.7866 - val_loss: 1.9359 - val_categorical_accuracy: 0.6938\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.80442\n",
      "Epoch 29/30\n",
      "547/547 - 92s - loss: 0.8224 - categorical_accuracy: 0.7871 - val_loss: 1.9324 - val_categorical_accuracy: 0.6935\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.80442\n",
      "Epoch 30/30\n",
      "547/547 - 93s - loss: 0.8206 - categorical_accuracy: 0.7871 - val_loss: 1.9569 - val_categorical_accuracy: 0.6864\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.80442\n"
     ]
    }
   ],
   "source": [
    "# summarize defined model\n",
    "print(gru_lstm.summary())\n",
    "plot_model(gru_lstm, to_file='gru_lstm.png', show_shapes=True)\n",
    "# fit model\n",
    "filename = 'gru_lstm.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history_gru_lstm = gru_lstm.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(validX, validY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  categorical_accuracy  val_loss  val_categorical_accuracy\n",
      "0   3.252434              0.535098  2.765865                  0.575057\n",
      "1   2.497374              0.601127  2.447517                  0.613943\n",
      "2   2.123063              0.636559  2.207898                  0.641400\n",
      "3   1.850369              0.660959  2.089215                  0.651429\n",
      "4   1.630965              0.681522  2.006674                  0.662886\n",
      "5   1.456967              0.699527  1.970055                  0.668371\n",
      "6   1.337380              0.712902  1.926979                  0.672800\n",
      "7   1.223832              0.727918  1.920150                  0.677314\n",
      "8   1.142345              0.739245  1.918651                  0.680000\n",
      "9   1.073350              0.750331  1.911030                  0.680629\n",
      "10  1.012037              0.760049  1.920534                  0.680771\n",
      "11  0.960292              0.769069  1.928720                  0.677171\n",
      "12  0.922774              0.775514  1.929744                  0.683429\n",
      "13  0.888299              0.781335  1.936129                  0.683057\n",
      "14  0.872083              0.784482  1.950822                  0.681543\n",
      "15  0.847296              0.788069  1.972288                  0.687114\n",
      "16  0.820223              0.792894  1.965000                  0.685486\n",
      "17  0.794701              0.797327  1.990011                  0.681743\n",
      "18  0.777706              0.801522  2.006792                  0.683057\n",
      "19  0.775307              0.801612  2.017063                  0.681086\n",
      "20  0.791487              0.800318  2.027573                  0.683171\n",
      "21  0.774285              0.802767  2.034509                  0.681971\n",
      "22  0.754439              0.807061  2.027456                  0.683571\n",
      "23  0.741155              0.809188  2.067071                  0.684514\n",
      "24  0.744951              0.808608  2.093328                  0.680143\n",
      "25  0.754910              0.806004  2.077359                  0.684429\n",
      "26  0.733570              0.811184  2.079852                  0.683114\n",
      "27  0.727032              0.811624  2.095391                  0.680200\n",
      "28  0.720308              0.813445  2.099010                  0.681371\n",
      "29  0.706425              0.814992  2.109025                  0.683229\n"
     ]
    }
   ],
   "source": [
    "df_history_gru_lstm = pd.DataFrame(history_both_lstm.history)\n",
    "df_history_gru_lstm.to_csv('df_history_gru_lstm.csv')\n",
    "print(df_history_gru_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "French(Source) : jai debranche la tele\n",
      "Target : i unplugged the tv\n",
      "Predicted : i have the tv \n",
      "\n",
      "French(Source) : je suis desolee davoir dit cela\n",
      "Target : im sorry i said that\n",
      "Predicted : im sorry i that \n",
      "\n",
      "French(Source) : jenfilai une chemise blanche\n",
      "Target : i wore a white shirt\n",
      "Predicted : i was a a \n",
      "\n",
      "French(Source) : il etait hors dhaleine\n",
      "Target : he was out of breath\n",
      "Predicted : he was very at \n",
      "\n",
      "French(Source) : cest un jour venteux\n",
      "Target : its a windy day\n",
      "Predicted : its a a huge \n",
      "\n",
      "French(Source) : je suis assez content\n",
      "Target : im happy enough\n",
      "Predicted : im pretty enough \n",
      "\n",
      "French(Source) : amusonsnous\n",
      "Target : lets have fun\n",
      "Predicted : lets have fun fun \n",
      "\n",
      "French(Source) : questce qui vous trouble\n",
      "Target : whats troubling you\n",
      "Predicted : what troubling you \n",
      "\n",
      "French(Source) : cest impossible\n",
      "Target : its impossible\n",
      "Predicted : this impossible \n",
      "\n",
      "French(Source) : personne ne change jamais\n",
      "Target : no one ever changes\n",
      "Predicted : no one ever \n",
      "\n",
      "French(Source) : ecoutetoi parler\n",
      "Target : listen to yourself\n",
      "Predicted : please wait \n",
      "\n",
      "French(Source) : je suis gave\n",
      "Target : im stuffed\n",
      "Predicted : im am \n",
      "\n",
      "French(Source) : cest jour pluvieux\n",
      "Target : its a rainy day\n",
      "Predicted : is a trouble \n",
      "\n",
      "French(Source) : ca a lair cher\n",
      "Target : that looks expensive\n",
      "Predicted : it sounds expensive \n",
      "\n",
      "French(Source) : je me suis reveille a\n",
      "Target : i woke up at\n",
      "Predicted : i woke rid \n",
      "\n",
      "French(Source) : combien de temps aije sommeille\n",
      "Target : how long did i sleep\n",
      "Predicted : how many you we it \n",
      "\n",
      "French(Source) : essaie de ne pas paniquer\n",
      "Target : try not to panic\n",
      "Predicted : try not not \n",
      "\n",
      "French(Source) : je fermai mon parapluie\n",
      "Target : i closed my umbrella\n",
      "Predicted : i my my umbrella \n",
      "\n",
      "French(Source) : cest toi le prisonnier\n",
      "Target : youre the prisoner\n",
      "Predicted : youre is prisoner \n",
      "\n",
      "French(Source) : tom a une grande bouche\n",
      "Target : tom has a big mouth\n",
      "Predicted : tom has a good \n",
      "\n",
      "French(Source) : nous sommes tout a fait seules\n",
      "Target : were quite alone\n",
      "Predicted : were all everything \n",
      "\n",
      "French(Source) : je dois trouver ca\n",
      "Target : i have to find that\n",
      "Predicted : i have to do that \n",
      "\n",
      "French(Source) : estce que tom vous connait\n",
      "Target : does tom know you\n",
      "Predicted : does tom know you \n",
      "\n",
      "French(Source) : que peuventils faire\n",
      "Target : what can they do\n",
      "Predicted : what can we do \n",
      "\n",
      "French(Source) : personne ne vient\n",
      "Target : no one is coming\n",
      "Predicted : no one one \n",
      "\n",
      "French(Source) : tu sais que je taime\n",
      "Target : you know i love you\n",
      "Predicted : you know i love tired \n",
      "\n",
      "French(Source) : tu es fiable\n",
      "Target : youre trustworthy\n",
      "Predicted : youre trustworthy \n",
      "\n",
      "French(Source) : cest chouette\n",
      "Target : this is nice\n",
      "Predicted : this is \n",
      "\n",
      "French(Source) : arretezvous ou vous etes\n",
      "Target : stop where you are\n",
      "Predicted : please are are \n",
      "\n",
      "French(Source) : lecole est finie\n",
      "Target : school is over\n",
      "Predicted : school is \n",
      "\n",
      "French(Source) : je netais pas prepare\n",
      "Target : i was unprepared\n",
      "Predicted : i wasnt unprepared \n",
      "\n",
      "French(Source) : nous sommes seules\n",
      "Target : were alone\n",
      "Predicted : were alone \n",
      "\n",
      "French(Source) : je vais te la preter\n",
      "Target : ill lend it to you\n",
      "Predicted : ill lend you to \n",
      "\n",
      "French(Source) : je pense que tes dingue\n",
      "Target : i think youre nuts\n",
      "Predicted : i think youre nuts \n",
      "\n",
      "French(Source) : cest ce a quoi nous nous attendions\n",
      "Target : its what we expected\n",
      "Predicted : what is it so \n",
      "\n",
      "French(Source) : tom continuait a parler\n",
      "Target : tom kept talking\n",
      "Predicted : tom kept talking \n",
      "\n",
      "French(Source) : jai de serieux doutes\n",
      "Target : i have serious doubts\n",
      "Predicted : i have sad \n",
      "\n",
      "French(Source) : nous avons de la compagnie\n",
      "Target : weve got company\n",
      "Predicted : we have company \n",
      "\n",
      "French(Source) : arretezvous juste la\n",
      "Target : stop right there\n",
      "Predicted : please right here \n",
      "\n",
      "French(Source) : tom fait ses bagages\n",
      "Target : toms packing\n",
      "Predicted : tom packing \n",
      "\n",
      "French(Source) : je fais de mon mieux\n",
      "Target : im doing my best\n",
      "Predicted : i feel my best \n",
      "\n",
      "French(Source) : tom aimetil son travail\n",
      "Target : does tom like his job\n",
      "Predicted : does tom like to \n",
      "\n",
      "French(Source) : on ma tendu un piege\n",
      "Target : i was framed\n",
      "Predicted : i had framed \n",
      "\n",
      "French(Source) : sagitil dun cancer\n",
      "Target : is it cancer\n",
      "Predicted : is it a difference \n",
      "\n",
      "French(Source) : nous avons ete tres prudents\n",
      "Target : we were very careful\n",
      "Predicted : were was very \n",
      "\n",
      "French(Source) : il prit un jour de conge\n",
      "Target : he took a day off\n",
      "Predicted : he disliked a a \n",
      "\n",
      "French(Source) : fais une pause\n",
      "Target : take a breather\n",
      "Predicted : make a breather \n",
      "\n",
      "French(Source) : questce que cest\n",
      "Target : what is it\n",
      "Predicted : what is \n",
      "\n",
      "French(Source) : aideznous tom\n",
      "Target : help us tom\n",
      "Predicted : help us \n",
      "\n",
      "French(Source) : vous vous etes fait avoir\n",
      "Target : youve been had\n",
      "Predicted : youve look like \n",
      "\n",
      "BLEU-1: 0.600466\n",
      "BLEU-2: 0.465210\n",
      "BLEU-3: 0.391904\n",
      "BLEU-4: 0.240162\n",
      "test\n",
      "French(Source) : la pendule sarreta\n",
      "Target : the clock stopped\n",
      "Predicted : the the is \n",
      "\n",
      "French(Source) : elles grandiront\n",
      "Target : theyll grow\n",
      "Predicted : theyre watching \n",
      "\n",
      "French(Source) : vous etes tous heureux\n",
      "Target : youre all happy\n",
      "Predicted : youre all happy \n",
      "\n",
      "French(Source) : je dors comme une pierre\n",
      "Target : im a sound sleeper\n",
      "Predicted : i dislike like a a \n",
      "\n",
      "French(Source) : noussommestousretraites\n",
      "Target : were all retired\n",
      "Predicted : lets \n",
      "\n",
      "French(Source) : celuila estil a vendre\n",
      "Target : is that one for sale\n",
      "Predicted : is is a camera \n",
      "\n",
      "French(Source) : les hommes se rendent au travail\n",
      "Target : the men go to work\n",
      "Predicted : evil are like the work \n",
      "\n",
      "French(Source) : jai deux neveux\n",
      "Target : i have two nephews\n",
      "Predicted : i have potato chips \n",
      "\n",
      "French(Source) : ma sur pleure souvent\n",
      "Target : my sister often cries\n",
      "Predicted : get go of of \n",
      "\n",
      "French(Source) : cest simple\n",
      "Target : thats simple\n",
      "Predicted : thats very \n",
      "\n",
      "French(Source) : tom adorait ca\n",
      "Target : tom loved it\n",
      "Predicted : tom used that \n",
      "\n",
      "French(Source) : ca serait tres bien\n",
      "Target : that would be fine\n",
      "Predicted : it is so good \n",
      "\n",
      "French(Source) : etesvous jalouses\n",
      "Target : are you jealous\n",
      "Predicted : are you happy \n",
      "\n",
      "French(Source) : les huskies sont sympathiques\n",
      "Target : huskies are friendly\n",
      "Predicted : utilities are yellow \n",
      "\n",
      "French(Source) : regarde ou tu poses le pied\n",
      "Target : watch your step\n",
      "Predicted : look at you \n",
      "\n",
      "French(Source) : merci detre venu\n",
      "Target : thanks for coming\n",
      "Predicted : thank for coming \n",
      "\n",
      "French(Source) : ta migraine est passee\n",
      "Target : is your headache gone\n",
      "Predicted : your your waste \n",
      "\n",
      "French(Source) : je suis parfaitement heureux\n",
      "Target : im perfectly happy\n",
      "Predicted : im happy happy \n",
      "\n",
      "French(Source) : personne ne peut marreter\n",
      "Target : no one can stop me\n",
      "Predicted : no one stop \n",
      "\n",
      "French(Source) : jaime ma maman\n",
      "Target : i love my mom\n",
      "Predicted : i like to \n",
      "\n",
      "French(Source) : sortez si vous pouvez\n",
      "Target : get out if you can\n",
      "Predicted : get me if to \n",
      "\n",
      "French(Source) : verifie ton chapeau\n",
      "Target : check your hat\n",
      "Predicted : remove your room book \n",
      "\n",
      "French(Source) : tom dessine bien\n",
      "Target : tom draws well\n",
      "Predicted : tom is well \n",
      "\n",
      "French(Source) : thomas avertit marie\n",
      "Target : tom warned mary\n",
      "Predicted : tom phoned mary \n",
      "\n",
      "French(Source) : je pensais que vous seriez daccord\n",
      "Target : i thought youd agree\n",
      "Predicted : i thought you you you \n",
      "\n",
      "French(Source) : recrutestu\n",
      "Target : are you hiring\n",
      "Predicted : lets \n",
      "\n",
      "French(Source) : je me bats mal\n",
      "Target : i fight badly\n",
      "Predicted : i am watching \n",
      "\n",
      "French(Source) : suisje soupconne\n",
      "Target : am i under suspicion\n",
      "Predicted : am i slipping \n",
      "\n",
      "French(Source) : pourquoi tom atil ete tue\n",
      "Target : why was tom killed\n",
      "Predicted : why is tom tom \n",
      "\n",
      "French(Source) : je sais que tom est lent\n",
      "Target : i know tom is slow\n",
      "Predicted : i know tom is \n",
      "\n",
      "French(Source) : vous aurez besoin de ceci\n",
      "Target : youll need this\n",
      "Predicted : you need to this \n",
      "\n",
      "French(Source) : laissezle seul\n",
      "Target : leave him alone\n",
      "Predicted : does it \n",
      "\n",
      "French(Source) : je vous avais prevenue\n",
      "Target : i did warn you\n",
      "Predicted : i forgot you you \n",
      "\n",
      "French(Source) : allons dans ta chambre\n",
      "Target : lets go to your room\n",
      "Predicted : lets get your room \n",
      "\n",
      "French(Source) : je me suis levee il y a une heure\n",
      "Target : i got up an hour ago\n",
      "Predicted : i have a a hour \n",
      "\n",
      "French(Source) : il faut que je dorme\n",
      "Target : i have to sleep\n",
      "Predicted : i wanted to \n",
      "\n",
      "French(Source) : je me suis senti exclue\n",
      "Target : i felt left out\n",
      "Predicted : i felt with \n",
      "\n",
      "French(Source) : je reviens\n",
      "Target : ill come back\n",
      "Predicted : ill be \n",
      "\n",
      "French(Source) : nayez pas lair si choquees\n",
      "Target : dont look so shocked\n",
      "Predicted : dont so so \n",
      "\n",
      "French(Source) : elle na pas peur\n",
      "Target : she has no fear\n",
      "Predicted : she works afraid \n",
      "\n",
      "French(Source) : je ne suis plus fatigue\n",
      "Target : im no longer tired\n",
      "Predicted : im am tired \n",
      "\n",
      "French(Source) : je deteste les longs au revoir\n",
      "Target : i hate long goodbyes\n",
      "Predicted : i hate them \n",
      "\n",
      "French(Source) : sortez\n",
      "Target : get out\n",
      "Predicted : get out \n",
      "\n",
      "French(Source) : tom fit un pas en avant\n",
      "Target : tom stepped forward\n",
      "Predicted : tom isnt a \n",
      "\n",
      "French(Source) : il est en train de vous regarder\n",
      "Target : hes looking at you\n",
      "Predicted : its looking at \n",
      "\n",
      "French(Source) : pars demain\n",
      "Target : leave tomorrow\n",
      "Predicted : open tomorrow tomorrow \n",
      "\n",
      "French(Source) : je vous ai deja paye\n",
      "Target : ive already paid you\n",
      "Predicted : i already got \n",
      "\n",
      "French(Source) : elle laca ses chaussures\n",
      "Target : she laced her shoes\n",
      "Predicted : she lost my hands \n",
      "\n",
      "French(Source) : il ny a pas le feu au lac\n",
      "Target : there is no hurry\n",
      "Predicted : he sat quarter the \n",
      "\n",
      "French(Source) : jai deux tickets\n",
      "Target : i have two tickets\n",
      "Predicted : i have potato chips \n",
      "\n",
      "BLEU-1: 0.471683\n",
      "BLEU-2: 0.330921\n",
      "BLEU-3: 0.264085\n",
      "BLEU-4: 0.143882\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "gru_lstm = load_model('gru_lstm.h5')\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "bleu_train_gru_lstm = evaluate_model(gru_lstm, eng_tokenizer, trainX, train)\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "bleu_test_gru_lstm = evaluate_model(gru_lstm, eng_tokenizer, testX, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4:  Encoder LSTM and Decoder GRU cell\n",
    "\n",
    "def lstm_gru(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "\tlearning_rate = 1e-2\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "\tmodel.add(LSTM(n_units))\n",
    "\tmodel.add(RepeatVector(tar_timesteps))\n",
    "\tmodel.add(GRU(n_units,return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "learning_rate = 1e-2\n",
    "lstm_gru = lstm_gru(fre_vocab_size, eng_vocab_size, fre_length, eng_length, 256)\n",
    "lstm_gru.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 14, 256)           3119104   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 7, 256)            394752    \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 7, 6010)           1544570   \n",
      "=================================================================\n",
      "Total params: 5,583,738\n",
      "Trainable params: 5,583,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n",
      "Epoch 1/30\n",
      "547/547 - 103s - loss: 3.1877 - categorical_accuracy: 0.5361 - val_loss: 2.7394 - val_categorical_accuracy: 0.5746\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.73940, saving model to lstm_gru.h5\n",
      "Epoch 2/30\n",
      "547/547 - 87s - loss: 2.4194 - categorical_accuracy: 0.6089 - val_loss: 2.2834 - val_categorical_accuracy: 0.6299\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.73940 to 2.28342, saving model to lstm_gru.h5\n",
      "Epoch 3/30\n",
      "547/547 - 88s - loss: 1.9815 - categorical_accuracy: 0.6470 - val_loss: 2.0489 - val_categorical_accuracy: 0.6511\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.28342 to 2.04890, saving model to lstm_gru.h5\n",
      "Epoch 4/30\n",
      "547/547 - 91s - loss: 1.6901 - categorical_accuracy: 0.6712 - val_loss: 1.9383 - val_categorical_accuracy: 0.6586\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.04890 to 1.93831, saving model to lstm_gru.h5\n",
      "Epoch 5/30\n",
      "547/547 - 92s - loss: 1.4832 - categorical_accuracy: 0.6906 - val_loss: 1.8752 - val_categorical_accuracy: 0.6709\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.93831 to 1.87517, saving model to lstm_gru.h5\n",
      "Epoch 6/30\n",
      "547/547 - 95s - loss: 1.3325 - categorical_accuracy: 0.7075 - val_loss: 1.8407 - val_categorical_accuracy: 0.6749\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.87517 to 1.84066, saving model to lstm_gru.h5\n",
      "Epoch 7/30\n",
      "547/547 - 91s - loss: 1.2205 - categorical_accuracy: 0.7220 - val_loss: 1.8290 - val_categorical_accuracy: 0.6803\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.84066 to 1.82896, saving model to lstm_gru.h5\n",
      "Epoch 8/30\n",
      "547/547 - 90s - loss: 1.1326 - categorical_accuracy: 0.7361 - val_loss: 1.8153 - val_categorical_accuracy: 0.6823\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.82896 to 1.81533, saving model to lstm_gru.h5\n",
      "Epoch 9/30\n",
      "547/547 - 86s - loss: 1.0633 - categorical_accuracy: 0.7458 - val_loss: 1.8229 - val_categorical_accuracy: 0.6861\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.81533\n",
      "Epoch 10/30\n",
      "547/547 - 85s - loss: 1.0101 - categorical_accuracy: 0.7553 - val_loss: 1.8061 - val_categorical_accuracy: 0.6894\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.81533 to 1.80608, saving model to lstm_gru.h5\n",
      "Epoch 11/30\n",
      "547/547 - 85s - loss: 0.9746 - categorical_accuracy: 0.7609 - val_loss: 1.8220 - val_categorical_accuracy: 0.6867\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.80608\n",
      "Epoch 12/30\n",
      "547/547 - 85s - loss: 0.9419 - categorical_accuracy: 0.7652 - val_loss: 1.8235 - val_categorical_accuracy: 0.6834\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.80608\n",
      "Epoch 13/30\n",
      "547/547 - 86s - loss: 0.9041 - categorical_accuracy: 0.7722 - val_loss: 1.8224 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.80608\n",
      "Epoch 14/30\n",
      "547/547 - 94s - loss: 0.8771 - categorical_accuracy: 0.7782 - val_loss: 1.8342 - val_categorical_accuracy: 0.6870\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.80608\n",
      "Epoch 15/30\n",
      "547/547 - 93s - loss: 0.8643 - categorical_accuracy: 0.7795 - val_loss: 1.8647 - val_categorical_accuracy: 0.6861\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.80608\n",
      "Epoch 16/30\n",
      "547/547 - 88s - loss: 0.8464 - categorical_accuracy: 0.7836 - val_loss: 1.8590 - val_categorical_accuracy: 0.6866\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.80608\n",
      "Epoch 17/30\n",
      "547/547 - 85s - loss: 0.8391 - categorical_accuracy: 0.7850 - val_loss: 1.8700 - val_categorical_accuracy: 0.6903\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.80608\n",
      "Epoch 18/30\n",
      "547/547 - 85s - loss: 0.8209 - categorical_accuracy: 0.7878 - val_loss: 1.8700 - val_categorical_accuracy: 0.6894\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.80608\n",
      "Epoch 19/30\n",
      "547/547 - 86s - loss: 0.8009 - categorical_accuracy: 0.7916 - val_loss: 1.8825 - val_categorical_accuracy: 0.6943\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.80608\n",
      "Epoch 20/30\n",
      "547/547 - 86s - loss: 0.7886 - categorical_accuracy: 0.7948 - val_loss: 1.8947 - val_categorical_accuracy: 0.6849\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.80608\n",
      "Epoch 21/30\n",
      "547/547 - 91s - loss: 0.7935 - categorical_accuracy: 0.7929 - val_loss: 1.8843 - val_categorical_accuracy: 0.6891\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.80608\n",
      "Epoch 22/30\n",
      "547/547 - 89s - loss: 0.7870 - categorical_accuracy: 0.7940 - val_loss: 1.9200 - val_categorical_accuracy: 0.6919\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.80608\n",
      "Epoch 23/30\n",
      "547/547 - 91s - loss: 0.7853 - categorical_accuracy: 0.7936 - val_loss: 1.9383 - val_categorical_accuracy: 0.6835\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.80608\n",
      "Epoch 24/30\n",
      "547/547 - 89s - loss: 0.7809 - categorical_accuracy: 0.7955 - val_loss: 1.9504 - val_categorical_accuracy: 0.6857\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.80608\n",
      "Epoch 25/30\n",
      "547/547 - 88s - loss: 0.7630 - categorical_accuracy: 0.7989 - val_loss: 1.9373 - val_categorical_accuracy: 0.6928\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.80608\n",
      "Epoch 26/30\n",
      "547/547 - 90s - loss: 0.7592 - categorical_accuracy: 0.8003 - val_loss: 1.9491 - val_categorical_accuracy: 0.6919\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.80608\n",
      "Epoch 27/30\n",
      "547/547 - 92s - loss: 0.7496 - categorical_accuracy: 0.8016 - val_loss: 1.9500 - val_categorical_accuracy: 0.6913\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.80608\n",
      "Epoch 28/30\n",
      "547/547 - 92s - loss: 0.7449 - categorical_accuracy: 0.8020 - val_loss: 1.9661 - val_categorical_accuracy: 0.6855\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.80608\n",
      "Epoch 29/30\n",
      "547/547 - 94s - loss: 0.7330 - categorical_accuracy: 0.8052 - val_loss: 1.9748 - val_categorical_accuracy: 0.6918\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.80608\n",
      "Epoch 30/30\n",
      "547/547 - 90s - loss: 0.7358 - categorical_accuracy: 0.8043 - val_loss: 1.9749 - val_categorical_accuracy: 0.6858\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.80608\n"
     ]
    }
   ],
   "source": [
    "# summarize defined model\n",
    "print(lstm_gru.summary())\n",
    "plot_model(lstm_gru, to_file='lstm_gru.png', show_shapes=True)\n",
    "\n",
    "# fit model\n",
    "filename = 'lstm_gru.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "history_lstm_gru = lstm_gru.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(validX, validY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  categorical_accuracy  val_loss  val_categorical_accuracy\n",
      "0   3.252434              0.535098  2.765865                  0.575057\n",
      "1   2.497374              0.601127  2.447517                  0.613943\n",
      "2   2.123063              0.636559  2.207898                  0.641400\n",
      "3   1.850369              0.660959  2.089215                  0.651429\n",
      "4   1.630965              0.681522  2.006674                  0.662886\n",
      "5   1.456967              0.699527  1.970055                  0.668371\n",
      "6   1.337380              0.712902  1.926979                  0.672800\n",
      "7   1.223832              0.727918  1.920150                  0.677314\n",
      "8   1.142345              0.739245  1.918651                  0.680000\n",
      "9   1.073350              0.750331  1.911030                  0.680629\n",
      "10  1.012037              0.760049  1.920534                  0.680771\n",
      "11  0.960292              0.769069  1.928720                  0.677171\n",
      "12  0.922774              0.775514  1.929744                  0.683429\n",
      "13  0.888299              0.781335  1.936129                  0.683057\n",
      "14  0.872083              0.784482  1.950822                  0.681543\n",
      "15  0.847296              0.788069  1.972288                  0.687114\n",
      "16  0.820223              0.792894  1.965000                  0.685486\n",
      "17  0.794701              0.797327  1.990011                  0.681743\n",
      "18  0.777706              0.801522  2.006792                  0.683057\n",
      "19  0.775307              0.801612  2.017063                  0.681086\n",
      "20  0.791487              0.800318  2.027573                  0.683171\n",
      "21  0.774285              0.802767  2.034509                  0.681971\n",
      "22  0.754439              0.807061  2.027456                  0.683571\n",
      "23  0.741155              0.809188  2.067071                  0.684514\n",
      "24  0.744951              0.808608  2.093328                  0.680143\n",
      "25  0.754910              0.806004  2.077359                  0.684429\n",
      "26  0.733570              0.811184  2.079852                  0.683114\n",
      "27  0.727032              0.811624  2.095391                  0.680200\n",
      "28  0.720308              0.813445  2.099010                  0.681371\n",
      "29  0.706425              0.814992  2.109025                  0.683229\n"
     ]
    }
   ],
   "source": [
    "df_history_lstm_gru = pd.DataFrame(history_both_lstm.history)\n",
    "df_history_lstm_gru.to_csv('df_history_lstm_gru.csv')\n",
    "print(df_history_lstm_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "French(Source) : jai debranche la tele\n",
      "Target : i unplugged the tv\n",
      "Predicted : i accepted the tv \n",
      "\n",
      "French(Source) : je suis desolee davoir dit cela\n",
      "Target : im sorry i said that\n",
      "Predicted : im sorry sorry said that \n",
      "\n",
      "French(Source) : jenfilai une chemise blanche\n",
      "Target : i wore a white shirt\n",
      "Predicted : he is a shirt shirt \n",
      "\n",
      "French(Source) : il etait hors dhaleine\n",
      "Target : he was out of breath\n",
      "Predicted : he was in to \n",
      "\n",
      "French(Source) : cest un jour venteux\n",
      "Target : its a windy day\n",
      "Predicted : this a a a \n",
      "\n",
      "French(Source) : je suis assez content\n",
      "Target : im happy enough\n",
      "Predicted : im quite enough \n",
      "\n",
      "French(Source) : amusonsnous\n",
      "Target : lets have fun\n",
      "Predicted : lets have in \n",
      "\n",
      "French(Source) : questce qui vous trouble\n",
      "Target : whats troubling you\n",
      "Predicted : what troubling you \n",
      "\n",
      "French(Source) : cest impossible\n",
      "Target : its impossible\n",
      "Predicted : its is \n",
      "\n",
      "French(Source) : personne ne change jamais\n",
      "Target : no one ever changes\n",
      "Predicted : no one ever \n",
      "\n",
      "French(Source) : ecoutetoi parler\n",
      "Target : listen to yourself\n",
      "Predicted : let me to \n",
      "\n",
      "French(Source) : je suis gave\n",
      "Target : im stuffed\n",
      "Predicted : ive all \n",
      "\n",
      "French(Source) : cest jour pluvieux\n",
      "Target : its a rainy day\n",
      "Predicted : its is of day \n",
      "\n",
      "French(Source) : ca a lair cher\n",
      "Target : that looks expensive\n",
      "Predicted : it feels expensive \n",
      "\n",
      "French(Source) : je me suis reveille a\n",
      "Target : i woke up at\n",
      "Predicted : i woke to back back \n",
      "\n",
      "French(Source) : combien de temps aije sommeille\n",
      "Target : how long did i sleep\n",
      "Predicted : i long i i lose \n",
      "\n",
      "French(Source) : essaie de ne pas paniquer\n",
      "Target : try not to panic\n",
      "Predicted : try try go panic panic \n",
      "\n",
      "French(Source) : je fermai mon parapluie\n",
      "Target : i closed my umbrella\n",
      "Predicted : i washed my umbrella \n",
      "\n",
      "French(Source) : cest toi le prisonnier\n",
      "Target : youre the prisoner\n",
      "Predicted : youre in in \n",
      "\n",
      "French(Source) : tom a une grande bouche\n",
      "Target : tom has a big mouth\n",
      "Predicted : tom has a mouth mouth \n",
      "\n",
      "French(Source) : nous sommes tout a fait seules\n",
      "Target : were quite alone\n",
      "Predicted : were quite alone \n",
      "\n",
      "French(Source) : je dois trouver ca\n",
      "Target : i have to find that\n",
      "Predicted : i wanted to hear that \n",
      "\n",
      "French(Source) : estce que tom vous connait\n",
      "Target : does tom know you\n",
      "Predicted : does tom know you \n",
      "\n",
      "French(Source) : que peuventils faire\n",
      "Target : what can they do\n",
      "Predicted : what could you to \n",
      "\n",
      "French(Source) : personne ne vient\n",
      "Target : no one is coming\n",
      "Predicted : no one listened \n",
      "\n",
      "French(Source) : tu sais que je taime\n",
      "Target : you know i love you\n",
      "Predicted : you know know you \n",
      "\n",
      "French(Source) : tu es fiable\n",
      "Target : youre trustworthy\n",
      "Predicted : youre trustworthy \n",
      "\n",
      "French(Source) : cest chouette\n",
      "Target : this is nice\n",
      "Predicted : its is \n",
      "\n",
      "French(Source) : arretezvous ou vous etes\n",
      "Target : stop where you are\n",
      "Predicted : we are you \n",
      "\n",
      "French(Source) : lecole est finie\n",
      "Target : school is over\n",
      "Predicted : school is is \n",
      "\n",
      "French(Source) : je netais pas prepare\n",
      "Target : i was unprepared\n",
      "Predicted : i was unprepared \n",
      "\n",
      "French(Source) : nous sommes seules\n",
      "Target : were alone\n",
      "Predicted : were alone \n",
      "\n",
      "French(Source) : je vais te la preter\n",
      "Target : ill lend it to you\n",
      "Predicted : ill lend to to her \n",
      "\n",
      "French(Source) : je pense que tes dingue\n",
      "Target : i think youre nuts\n",
      "Predicted : i think youre nuts \n",
      "\n",
      "French(Source) : cest ce a quoi nous nous attendions\n",
      "Target : its what we expected\n",
      "Predicted : what is you expected mean \n",
      "\n",
      "French(Source) : tom continuait a parler\n",
      "Target : tom kept talking\n",
      "Predicted : tom kept talking \n",
      "\n",
      "French(Source) : jai de serieux doutes\n",
      "Target : i have serious doubts\n",
      "Predicted : i have doubts doubts \n",
      "\n",
      "French(Source) : nous avons de la compagnie\n",
      "Target : weve got company\n",
      "Predicted : we kept the \n",
      "\n",
      "French(Source) : arretezvous juste la\n",
      "Target : stop right there\n",
      "Predicted : stop right here \n",
      "\n",
      "French(Source) : tom fait ses bagages\n",
      "Target : toms packing\n",
      "Predicted : tom packing packing \n",
      "\n",
      "French(Source) : je fais de mon mieux\n",
      "Target : im doing my best\n",
      "Predicted : ive doing my best \n",
      "\n",
      "French(Source) : tom aimetil son travail\n",
      "Target : does tom like his job\n",
      "Predicted : does tom sold do job \n",
      "\n",
      "French(Source) : on ma tendu un piege\n",
      "Target : i was framed\n",
      "Predicted : i was framed framed \n",
      "\n",
      "French(Source) : sagitil dun cancer\n",
      "Target : is it cancer\n",
      "Predicted : is it a \n",
      "\n",
      "French(Source) : nous avons ete tres prudents\n",
      "Target : we were very careful\n",
      "Predicted : we were careful \n",
      "\n",
      "French(Source) : il prit un jour de conge\n",
      "Target : he took a day off\n",
      "Predicted : he took a day day \n",
      "\n",
      "French(Source) : fais une pause\n",
      "Target : take a breather\n",
      "Predicted : take a water break \n",
      "\n",
      "French(Source) : questce que cest\n",
      "Target : what is it\n",
      "Predicted : what this \n",
      "\n",
      "French(Source) : aideznous tom\n",
      "Target : help us tom\n",
      "Predicted : help tom tom \n",
      "\n",
      "French(Source) : vous vous etes fait avoir\n",
      "Target : youve been had\n",
      "Predicted : youre are us \n",
      "\n",
      "BLEU-1: 0.638371\n",
      "BLEU-2: 0.500743\n",
      "BLEU-3: 0.424814\n",
      "BLEU-4: 0.268242\n",
      "test\n",
      "French(Source) : la pendule sarreta\n",
      "Target : the clock stopped\n",
      "Predicted : the engine is \n",
      "\n",
      "French(Source) : elles grandiront\n",
      "Target : theyll grow\n",
      "Predicted : theyre escaping \n",
      "\n",
      "French(Source) : vous etes tous heureux\n",
      "Target : youre all happy\n",
      "Predicted : youre all happy \n",
      "\n",
      "French(Source) : je dors comme une pierre\n",
      "Target : im a sound sleeper\n",
      "Predicted : i wish a a kid \n",
      "\n",
      "French(Source) : noussommestousretraites\n",
      "Target : were all retired\n",
      "Predicted : lets me \n",
      "\n",
      "French(Source) : celuila estil a vendre\n",
      "Target : is that one for sale\n",
      "Predicted : is college my \n",
      "\n",
      "French(Source) : les hommes se rendent au travail\n",
      "Target : the men go to work\n",
      "Predicted : men men work work \n",
      "\n",
      "French(Source) : jai deux neveux\n",
      "Target : i have two nephews\n",
      "Predicted : i hate tenure \n",
      "\n",
      "French(Source) : ma sur pleure souvent\n",
      "Target : my sister often cries\n",
      "Predicted : my belongs to \n",
      "\n",
      "French(Source) : cest simple\n",
      "Target : thats simple\n",
      "Predicted : this is simple \n",
      "\n",
      "French(Source) : tom adorait ca\n",
      "Target : tom loved it\n",
      "Predicted : tom sold that that \n",
      "\n",
      "French(Source) : ca serait tres bien\n",
      "Target : that would be fine\n",
      "Predicted : that that be good \n",
      "\n",
      "French(Source) : etesvous jalouses\n",
      "Target : are you jealous\n",
      "Predicted : are you jealous \n",
      "\n",
      "French(Source) : les huskies sont sympathiques\n",
      "Target : huskies are friendly\n",
      "Predicted : the are are \n",
      "\n",
      "French(Source) : regarde ou tu poses le pied\n",
      "Target : watch your step\n",
      "Predicted : look me \n",
      "\n",
      "French(Source) : merci detre venu\n",
      "Target : thanks for coming\n",
      "Predicted : what being up \n",
      "\n",
      "French(Source) : ta migraine est passee\n",
      "Target : is your headache gone\n",
      "Predicted : is loaded loaded loaded \n",
      "\n",
      "French(Source) : je suis parfaitement heureux\n",
      "Target : im perfectly happy\n",
      "Predicted : im happy happy happy \n",
      "\n",
      "French(Source) : personne ne peut marreter\n",
      "Target : no one can stop me\n",
      "Predicted : no one can help \n",
      "\n",
      "French(Source) : jaime ma maman\n",
      "Target : i love my mom\n",
      "Predicted : i love my exam \n",
      "\n",
      "French(Source) : sortez si vous pouvez\n",
      "Target : get out if you can\n",
      "Predicted : try try if to help help \n",
      "\n",
      "French(Source) : verifie ton chapeau\n",
      "Target : check your hat\n",
      "Predicted : remove your hat \n",
      "\n",
      "French(Source) : tom dessine bien\n",
      "Target : tom draws well\n",
      "Predicted : tom writes \n",
      "\n",
      "French(Source) : thomas avertit marie\n",
      "Target : tom warned mary\n",
      "Predicted : tom rescued mary \n",
      "\n",
      "French(Source) : je pensais que vous seriez daccord\n",
      "Target : i thought youd agree\n",
      "Predicted : i thought youd agree \n",
      "\n",
      "French(Source) : recrutestu\n",
      "Target : are you hiring\n",
      "Predicted : lets donkey \n",
      "\n",
      "French(Source) : je me bats mal\n",
      "Target : i fight badly\n",
      "Predicted : i feel feel bad \n",
      "\n",
      "French(Source) : suisje soupconne\n",
      "Target : am i under suspicion\n",
      "Predicted : am i hired \n",
      "\n",
      "French(Source) : pourquoi tom atil ete tue\n",
      "Target : why was tom killed\n",
      "Predicted : why was tom \n",
      "\n",
      "French(Source) : je sais que tom est lent\n",
      "Target : i know tom is slow\n",
      "Predicted : i know tom is psyched \n",
      "\n",
      "French(Source) : vous aurez besoin de ceci\n",
      "Target : youll need this\n",
      "Predicted : you need need this \n",
      "\n",
      "French(Source) : laissezle seul\n",
      "Target : leave him alone\n",
      "Predicted : leave alone \n",
      "\n",
      "French(Source) : je vous avais prevenue\n",
      "Target : i did warn you\n",
      "Predicted : i call you \n",
      "\n",
      "French(Source) : allons dans ta chambre\n",
      "Target : lets go to your room\n",
      "Predicted : dont go in room room \n",
      "\n",
      "French(Source) : je me suis levee il y a une heure\n",
      "Target : i got up an hour ago\n",
      "Predicted : i got a a \n",
      "\n",
      "French(Source) : il faut que je dorme\n",
      "Target : i have to sleep\n",
      "Predicted : i need to to die \n",
      "\n",
      "French(Source) : je me suis senti exclue\n",
      "Target : i felt left out\n",
      "Predicted : i felt got \n",
      "\n",
      "French(Source) : je reviens\n",
      "Target : ill come back\n",
      "Predicted : i usually out \n",
      "\n",
      "French(Source) : nayez pas lair si choquees\n",
      "Target : dont look so shocked\n",
      "Predicted : were look so so \n",
      "\n",
      "French(Source) : elle na pas peur\n",
      "Target : she has no fear\n",
      "Predicted : she not fear \n",
      "\n",
      "French(Source) : je ne suis plus fatigue\n",
      "Target : im no longer tired\n",
      "Predicted : im only tired tired \n",
      "\n",
      "French(Source) : je deteste les longs au revoir\n",
      "Target : i hate long goodbyes\n",
      "Predicted : i hate find \n",
      "\n",
      "French(Source) : sortez\n",
      "Target : get out\n",
      "Predicted : get out \n",
      "\n",
      "French(Source) : tom fit un pas en avant\n",
      "Target : tom stepped forward\n",
      "Predicted : tom is tom \n",
      "\n",
      "French(Source) : il est en train de vous regarder\n",
      "Target : hes looking at you\n",
      "Predicted : hes is late \n",
      "\n",
      "French(Source) : pars demain\n",
      "Target : leave tomorrow\n",
      "Predicted : come tomorrow tomorrow \n",
      "\n",
      "French(Source) : je vous ai deja paye\n",
      "Target : ive already paid you\n",
      "Predicted : i paid you \n",
      "\n",
      "French(Source) : elle laca ses chaussures\n",
      "Target : she laced her shoes\n",
      "Predicted : she has her shoes \n",
      "\n",
      "French(Source) : il ny a pas le feu au lac\n",
      "Target : there is no hurry\n",
      "Predicted : there was in fly \n",
      "\n",
      "French(Source) : jai deux tickets\n",
      "Target : i have two tickets\n",
      "Predicted : i hate two \n",
      "\n",
      "BLEU-1: 0.477211\n",
      "BLEU-2: 0.329372\n",
      "BLEU-3: 0.262713\n",
      "BLEU-4: 0.144590\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "lstm_gru = load_model('lstm_gru.h5')\n",
    "\n",
    "# test on some training sequences\n",
    "print('train')\n",
    "bleu_train_lstm_gru = evaluate_model(lstm_gru, eng_tokenizer, trainX, train)\n",
    "\n",
    "# test on some test sequences\n",
    "print('test')\n",
    "bleu_test_lstm_gru = evaluate_model(lstm_gru, eng_tokenizer, testX, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
